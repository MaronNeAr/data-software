#### 大模型基础

###### 机器学习和深度学习

- 机器学习：监督学习、无监督学习与强化学习
- 深度学习：卷积神经网络（CNN）、循环神经网络（RNN）、Transformer网络等

###### 大模型的训练

- 大模型训练的三个阶段：预训练、SFT（监督微调）以及RLHF（基于人类反馈的强化学习）
- 预训练：学习不同种类的预料、学习到语言的统计规律和一般知识（局限性：只是补全句子，而没有领会人类的意图）
- SFT（监督微调）：专注于某一特定领域、学习专业的垂直领域知识，可以按照人类的意图回答专业领域的问题
- RLHF（基于人类反馈的强化学习）：根据各种正面反馈、负面反馈来对模型进行强化学习，使回答符合人类的偏好

###### 大模型的特点和分类

- 大模型的特点：
  - 规模和参数量大（数亿到数千亿）
  - 广泛的数据集的预训练（语言、图像）
  - 适应性和灵活性强（通过微调和少样本学习高效的迁移到各种下游任务、有较强的跨域能力）
  - 计算资源需求大（需要高昂的计算和资源需求，包括但不限于数据存储、训练时间、能量消耗和硬件）
- 大模型的分类：大语言模型（LLM）、多模态模型（计算机视觉模型、音频处理模型）
- 大语言模型（LLM）：专注于自然语言处理（NLP）、旨在处理语言、文章、对话等自然语言文本。通常基于深度学习架构，应用领域包括文本生成、问答系统、文本分类、机器翻对话系统
- 多模态模型：能够同时处理和理解不同感知通道（文本、图像、音频、视频等）的数据，进行跨模型推理、生成和理解任务，应用领域墨扩视觉问答、图像描述生成、跨模态检索

###### 大模型的工作流程

- 分词化分类：词粒度（英语）、字符粒度（汉字）、子词粒度（词根、词缀）
- 大语言模型生成文本的过程：
  - 概括：给定文本预测下一个token；
  - 过程：不是一步到位的，基于现有的token，根据概率最大原则预测出下一个最有可能的token，然后将该预测的token加入到输入序列中，然后将更新后的输入序列继续输入大模型预测下一个token（直到EOS），这个过程叫做自回归
