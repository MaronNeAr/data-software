## 第一章 线程安全性

#### 线程安全的定义

###### 原子性（Atomicity）、可见性（Visibility）、有序性（Ordering）

- 原子性指一个操作或多个操作要么全部执行且不可中断，要么完全不执行。**单个操作在多线程中不会被其他线程干扰**。
- 可见性指当一个线程修改了共享变量的值，其他线程能**立即感知到修改后的值**。若没有可见性保证，线程可能读取到旧数据。
- 有序性指程序执行的顺序按照代码的先后顺序执行。由于**指令重排序优化**（编译器或CPU为了提高性能对指令重新排序），代码的实际执行顺序可能与编写顺序不一致，可能导致多线程下的逻辑错误。

###### 三者的关系

- **原子性**：解决操作被中途打断的问题（如多个线程同时修改同一变量）。
- **可见性**：解决一个线程修改数据后其他线程看不到的问题。
- **有序性**：解决代码执行顺序不符合预期的问题。

###### 综合应用

- `synchronized`：同时保证原子性、可见性和有序性（锁的释放会强制同步主内存）。
- `volatile`：仅保证可见性和有序性，不保证原子性（适合单线程写、多线程读的场景）。
- `AtomicXXX`类：通过CAS保证原子性，同时隐含可见性（底层基于`volatile`）。

#### synchronized关键字与内置锁的机制

###### `synchronized`关键字的作用

- **原子性**：确保同一时刻只有一个线程能执行被锁保护的代码。
- **可见性**：线程释放锁时，会将本地内存的修改刷新到主内存；获取锁时，会清空本地内存并重新从主内存加载变量。
- **有序性**：禁止被`synchronized`包裹的代码块内的指令重排序（通过锁的“临界区”语义）。

###### `synchronized`的三种使用方式

- **修饰实例方法**

  - **锁对象**：当前实例对象（`this`）。

  - **作用范围**：同一实例的多个线程会互斥访问该方法。

- **修饰静态方法**

  - **锁对象**：当前类的`Class`对象（如`Counter.class`）。
  - **作用范围**：所有实例的线程都会互斥访问该静态方法。

- **修饰代码块**

  - **锁对象**：显式指定任意对象（通常是共享资源）。
  - **作用范围**：只有使用同一锁对象的线程才会互斥。

###### 内置锁的核心机制

- **锁的获取与释放**
  - **获取锁**：线程进入`synchronized`代码块或方法时，尝试获取锁。若锁已被其他线程占用，则当前线程进入阻塞状态（BLOCKED）。
  - **释放锁**：线程退出`synchronized`代码块（正常执行结束或抛出异常）时，自动释放锁。

- **可重入性（Reentrancy）**：同一个线程可以重复获取同一把锁。

- **锁的粒度**

  - **粗粒度锁**：锁住整个方法或大段代码（可能降低并发性能）。

  - **细粒度锁**：仅锁住必要的最小代码块（推荐做法）。

######  内置锁的底层实现

- **监视器锁（Monitor）**

  - 每个Java对象都与一个**监视器锁**关联，通过对象头中的标记（Mark Word）实现锁状态管理。

  - 线程进入`synchronized`代码块时，会尝试通过CAS操作获取锁；若失败则进入阻塞队列。

- **锁的升级优化**

  - **无锁状态**：初始状态。

  - **偏向锁（Biased Lock）**：当只有一个线程访问时，标记锁偏向该线程。

  - **轻量级锁（Lightweight Lock）**：多线程竞争不激烈时，通过CAS自旋尝试获取锁。

  - **重量级锁（Heavyweight Lock）**：竞争激烈时，升级为操作系统层面的互斥锁（Mutex）。

###### `synchronized`与其他同步机制的对比

| 特性                  | `synchronized`              | `ReentrantLock`            |
| :-------------------- | :-------------------------- | :------------------------- |
| 锁的获取方式          | 自动获取与释放              | 需手动`lock()`和`unlock()` |
| 可中断性              | 不支持                      | 支持`lockInterruptibly()`  |
| 公平锁                | 默认非公平                  | 可配置公平或非公平         |
| 条件变量（Condition） | 通过`wait()`/`notify()`实现 | 支持多个`Condition`        |
| 性能                  | JDK 6+优化后接近无锁性能    | 高竞争场景下性能更好       |

#### 竞态条件（Race Condition）

###### 竞态条件的两种典型场景

- **读取-修改-写入（Read-Modify-Write）**：线程需要先读取共享变量的值，基于该值进行计算，再写回新值。
- **先检查后执行（Check-Then-Act）**：根据某个检查结果（如“是否存在”）决定后续操作，但检查与执行之间共享状态可能被其他线程修改。

###### 避免竞态条件的方法

- **使用锁（`synchronized`）保证原子性**：通过锁将非原子操作转换为原子操作，确保同一时刻只有一个线程执行临界区代码。
- **使用原子类（Atomic Classes）**：基于CAS（Compare-And-Swap）实现无锁原子操作，避免锁的性能开销。
- **缩小同步代码块范围**：减少锁的持有时间，提升并发性能。
- **设计不可变对象（Immutability）**：不可变对象的状态无法被修改，无需同步。
- **线程封闭（Thread Confinement）**：将共享数据限制在单个线程内访问（如局部变量、`ThreadLocal`）。
- **使用并发容器**：直接使用线程安全的数据结构（如`ConcurrentHashMap`）。

## 第二章 对象的共享

#### 内存可见性

###### `volatile`关键字的核心作用

- **保证可见性**：对`volatile`变量的写操作立即刷新到主内存，读操作直接从主内存读取。
- **禁止指令重排序**：通过内存屏障（Memory Barrier）禁止编译器和处理器对`volatile`变量操作的指令重排序。

###### 可见性问题的根源

- **主内存（Main Memory）**：所有共享变量的存储区域。
- **线程工作内存（Working Memory）**：每个线程私有的缓存，存储其使用的变量的副本。
- **问题**：线程对变量的操作（读/写）优先在本地工作内存中进行，修改可能不会立即同步到主内存，导致其他线程无法感知变化。

###### `volatile`如何保证可见性

- **写入操作（Write）**

  - 线程对`volatile`变量的修改会**立即刷新到主内存**。

  - 强制使其他线程中该变量的缓存副本失效（通过缓存一致性协议，如MESI）。

- **读取操作（Read）**：每次读取`volatile`变量时，直接从**主内存加载最新值**，而非使用本地缓存。

###### `volatile`如何禁止指令重排序

- **写操作**：在写入 `volatile` 变量后，会插入一个 `StoreStore` 屏障，确保之前的普通写操作（比如对象初始化）先完成，再让 `volatile` 写操作对其他线程可见。
- **读操作**：在读取 `volatile` 变量前，会插入一个 `LoadLoad` 屏障，确保后续的普通读操作不会重排序到 `volatile` 读之前。

###### `volatile`的适用场景

- **状态标志位**：单线程写、多线程读的布尔标志，如控制线程退出。

- **一次性安全发布**：安全发布不可变对象（即使对象引用是`volatile`，其内部状态仍需不可变）。
- **低竞争下的独立变量**：单个变量的读写操作，且不依赖当前值（如`volatile int count`仅用于计数，不进行`count++`）。

###### `volatile`与`synchronized`对比

| 特性         | `volatile`                 | `synchronized`             |
| :----------- | :------------------------- | :------------------------- |
| **可见性**   | 保证                       | 保证                       |
| **原子性**   | 不保证复合操作             | 保证                       |
| **有序性**   | 禁止指令重排序             | 保证临界区内有序性         |
| **互斥性**   | 无                         | 有                         |
| **性能**     | 轻量级（无上下文切换）     | 重量级（锁竞争时性能下降） |
| **适用场景** | 单变量可见性、简单状态标志 | 复合操作、代码块同步       |

#### 安全发布对象的四种方式

###### 静态初始化（Static Initialization）

- **原理**：JVM在类加载阶段执行静态初始化（如静态块或静态变量赋值），且保证该过程**线程安全**。通过静态初始化创建的对象引用可被安全发布。
- **适用场景**：单例模式的饿汉式实现，或全局共享的不可变对象。
- **变体（静态内部类）**：延迟初始化且线程安全。

###### `volatile`关键字

- **原理**：`volatile`修饰的变量在写入时会**立即刷新到主内存**，且禁止指令重排序，确保其他线程看到完全初始化的对象。
- **适用场景**：双重检查锁定（Double-Checked Locking）实现延迟初始化。

###### `final`字段

- **原理**：`final`字段在构造函数中初始化完成后，JVM保证其值对所有线程可见（通过内存屏障）。对象引用安全发布后，其`final`字段的值不可变，线程安全。
- **适用场景**：不可变对象（如`String`、枚举类）的安全发布。

###### 通过锁机制安全发布

- **原理**：使用锁（如`synchronized`）或线程安全容器（如`ConcurrentHashMap`）发布对象，确保对象的修改和读取在同步块内完成，强制内存可见性。
- **适用场景**：动态更新的共享对象或集合。

###### 安全发布方式的对比与选择

| **方式**        | **适用场景**                 | **性能**       | **注意事项**                           |
| :-------------- | :--------------------------- | :------------- | :------------------------------------- |
| **静态初始化**  | 单例、全局不可变对象         | 高（无锁）     | 类加载时初始化，可能影响启动速度       |
| **`volatile`**  | 延迟初始化（如双重检查锁定） | 中（无锁竞争） | 仅适用于单次发布，不保证复合操作原子性 |
| **`final`字段** | 不可变对象                   | 高（无锁）     | 构造函数中禁止`this`逸出               |
| **锁机制/容器** | 动态更新的共享对象           | 低（锁竞争）   | 需覆盖所有访问路径                     |

#### 不可变对象（Immutable Objects）的设计与优势

######  不可变对象的定义

- 不可变对象是指**对象的状态在创建后不能被修改**，所有字段均为`final`，且构造过程中无`this`引用逸出

###### 不可变对象的设计原则

- **字段声明为`final`**：所有字段用`final`修饰，确保构造完成后无法修改。
- **不提供修改方法**：不暴露`setter`或其他修改内部状态的方法。
- **防止子类化**：将类声明为`final`，或隐藏构造函数（如私有构造器+工厂方法），避免子类破坏不可变性。
- **防止`this`逸出**：构造函数中避免将`this`传递给外部（如注册监听器或启动线程），否则其他线程可能访问到未完全初始化的对象。

###### 不可变对象的优势

- **线程安全**：对象状态不可变，多线程并发访问无需加锁，天然线程安全。
- **自由共享与缓存**：可安全缓存并重复使用（如`Integer.valueOf()`的缓存池）。
- **简化程序逻辑**：对象状态固定，调试和推理更简单，无需追踪状态变化路径。
- **安全发布**：通过`final`字段和JMM规则，对象构造完成后对其他线程立即可见。

## 第三章 基础构建模块

#### 并发容器

###### ConcurrentHashMap

- **设计原理**

  - **分段锁（JDK 7）**：将数据分成多个段（Segment），每个段独立加锁，不同段的操作可并行执行。

  - **CAS + synchronized（JDK 8+）**：取消分段锁，改用`CAS`（无锁算法）和细粒度`synchronized`锁桶（Node），进一步提升并发性能。

- **核心特性**

  - **线程安全**：支持多线程并发读写，无需外部同步。
  - **高吞吐量**：锁的粒度更细，减少线程竞争。
  - **弱一致性**：迭代器遍历时可能不反映最新修改（但不抛出`ConcurrentModificationException`）。

- **适用场景**

  - 高并发读写（如缓存、计数器）。
  - 替代`Hashtable`或`Collections.synchronizedMap`。

- **对比传统同步容器**

  | 特性             | `ConcurrentHashMap` | `Hashtable`/`synchronizedMap` |
  | :--------------- | :------------------ | :---------------------------- |
  | **锁粒度**       | 细粒度（桶级别）    | 粗粒度（整个表）              |
  | **并发性能**     | 高                  | 低                            |
  | **迭代器一致性** | 弱一致性            | 强一致性（可能抛出异常）      |

###### CopyOnWriteArrayList

- **设计原理**

  - **写时复制（Copy-On-Write）**：每次修改（增、删、改）时，复制底层数组，在新副本上操作，完成后替换原数组。

  - **读操作无锁**：直接访问原数组，无需同步。

  - **写操作加锁**：保证同一时刻只有一个线程修改。

- **核心特性**

  - **线程安全**：读操作完全无锁，写操作通过复制保证安全。
  - **数据一致性**：迭代器遍历的是创建时的数组快照，不反映后续修改。
  - **内存开销**：频繁修改会导致大量数组复制，占用内存。

- **适用场景**

  - **读多写极少**（如监听器列表、配置白名单）。

  - 替代`Collections.synchronizedList`，在读远多于写时性能更优。

- **对比传统同步容器**

  | 特性           | `CopyOnWriteArrayList` | `synchronizedList` |
  | :------------- | :--------------------- | :----------------- |
  | **读性能**     | 无锁，极高             | 需加锁，较低       |
  | **写性能**     | 复制数组，较低         | 直接修改，较高     |
  | **内存占用**   | 高（频繁写时）         | 低                 |
  | **数据一致性** | 快照一致性             | 强一致性           |

###### 并发容器适用场景

- **高并发读写** → `ConcurrentHashMap`

- **读多写极少** → `CopyOnWriteArrayList`
- **写多读少** → 考虑`ConcurrentLinkedQueue`或阻塞队列（如`LinkedBlockingQueue`）
- **强一致性需求** → 慎用`CopyOnWriteArrayList`，优先使用锁同步的容器。

#### 阻塞队列

###### Java阻塞队列

| **实现类**              | **数据结构**     | **特性**                                                     |
| :---------------------- | :--------------- | :----------------------------------------------------------- |
| `ArrayBlockingQueue`    | 数组             | 有界队列，固定容量，公平性可选（基于`ReentrantLock`）        |
| `LinkedBlockingQueue`   | 链表             | 可选有界或无界（默认`Integer.MAX_VALUE`），吞吐量通常更高    |
| `PriorityBlockingQueue` | 堆（优先级队列） | 无界队列，元素按优先级排序（需实现`Comparable`或提供`Comparator`） |
| `SynchronousQueue`      | 无存储           | 直接传递队列，插入操作必须等待取出操作（无缓冲，适合线程间直接传递任务） |
| `DelayQueue`            | 堆（延迟队列）   | 无界队列，元素需实现`Delayed`接口，按到期时间排序（用于定时任务调度） |
| `LinkedTransferQueue`   | 链表             | 混合阻塞队列，支持`transfer`方法（生产者直接等待消费者取走元素） |

###### 阻塞队列的工作原理

- **线程安全机制**：内部通过`ReentrantLock`和`Condition`实现线程同步
- **锁分离**：插入和取出操作使用不同的锁（如`LinkedBlockingQueue`的`putLock`和`takeLock`），减少竞争。
- **条件变量**：队列空或满时，通过`Condition`的`await()`和`signal()`实现阻塞与唤醒。

###### 阻塞队列的典型使用场景

- **生产者-消费者模式**：适合任务量不可控但需快速响应的场景（如日志处理）。
- **线程池任务调度**：Java线程池（如`ThreadPoolExecutor`）默认使用`LinkedBlockingQueue`存储待执行任务。
- **流量削峰与系统解耦**：在高并发场景下，用队列缓冲瞬时流量，保护下游系统。

###### 阻塞队列的选择与调优

- **队列容量**

  - **有界队列**（如`ArrayBlockingQueue`）：避免内存溢出，但需合理设置容量，防止任务被拒绝。

  - **无界队列**（如`LinkedBlockingQueue`）：可能因任务堆积导致内存耗尽，需谨慎使用。

- **公平性**

  - 公平锁（`fairness=true`）减少线程饥饿，但降低吞吐量；非公平锁（默认）反之。

    ```
    ArrayBlockingQueue<Integer> fairQueue = new ArrayBlockingQueue<>(100, true);
    ```

- **特殊需求**

  - **优先级调度** → `PriorityBlockingQueue`

  - **延迟任务** → `DelayQueue`

  - **直接传递任务** → `SynchronousQueue`

###### 阻塞队列的常见问题

- **死锁风险**

  - **场景**：多个线程互相等待对方释放资源。

  - **解决**：使用超时方法（如`poll(timeout)`），避免无限阻塞。

- **资源耗尽**

  - **场景**：无界队列导致内存溢出。

  - **解决**：改用有界队列，配合拒绝策略（如线程池的`RejectedExecutionHandler`）。

- **性能瓶颈**

  - **场景**：队列成为系统吞吐量的瓶颈。

  - **解决**：优化队列类型（如`LinkedTransferQueue`提升吞吐量），或增加消费者线程。

#### 同步工具类

###### CountDownLatch

- **核心功能**

  - **一次性屏障**：允许一个或多个线程等待其他线程完成操作后再继续执行。

  - **计数器递减**：初始化时设定计数值（`count`），线程调用`countDown()`减少计数，计数归零时唤醒等待线程。

- **主要方法**

  - **`CountDownLatch(int count)`**：构造函数，指定初始计数。

  - **`await()`**：阻塞当前线程，直到计数归零。

  - **`countDown()`**：减少计数值，计数为0时唤醒所有等待线程。

- **使用场景**：主线程等待所有子任务完成；多线程等待同一事件触发（如模拟并发测试）

###### Semaphore

- **核心功能**

  - **控制资源访问的并发数**：通过许可证（`permits`）限制同时访问某资源的线程数量。

  - **可公平/非公平模式**：默认非公平，按请求顺序或竞争获取许可证。

- **主要方法**

  - **`Semaphore(int permits)`**：构造函数，指定许可证数量。

  - **`acquire()`**：获取许可证（若无可用则阻塞）。

  - **`release()`**：释放许可证。

  - **`tryAcquire()`**：非阻塞尝试获取许可证。

- **使用场景**：限流（如数据库连接池）；实现互斥锁（许可证为1的信号量）

###### CyclicBarrier

- **核心功能**

  - **可重置的屏障**：让一组线程相互等待，直到所有线程到达屏障点后同时继续执行。

  - **支持回调**：所有线程到达屏障后，可触发一个`Runnable`任务。

- **主要方法**

  - **`CyclicBarrier(int parties)`**：构造函数，指定参与的线程数。

  - **`CyclicBarrier(int parties, Runnable barrierAction)`**：指定到达屏障后的回调任务。

  - **`await()`**：线程到达屏障点并等待其他线程。

- **使用场景**：分阶段并行计算；多线程数据合并（如分布式计算）

###### 同步工具对比与选型

| **工具**         | **核心机制**           | **重用性** | **典型场景**                 |
| :--------------- | :--------------------- | :--------- | :--------------------------- |
| `CountDownLatch` | 等待其他线程完成       | 一次性     | 主线程等待子任务、并发触发   |
| `Semaphore`      | 控制资源访问并发数     | 可重用     | 限流、资源池（如数据库连接） |
| `CyclicBarrier`  | 多线程相互等待至屏障点 | 可重用     | 分阶段任务、数据合并         |

#### CompletableFuture

###### 核心特性

- **异步任务执行**：支持提交任务到线程池异步执行，避免阻塞主线程；适用于 I/O 操作、网络请求、并行计算等耗时任务。
- **链式操作与组合**：允许将多个异步任务串联或并联，形成任务流水线；支持结果转换、消费、错误处理等。
- **非阻塞与响应式**：通过回调机制避免线程阻塞，提升系统吞吐量。

###### 核心方法详解

- **创建 CompletableFuture**

  - **supplyAsync**：提交有返回值的异步任务。

  - **runAsync**：提交无返回值的异步任务。

- **链式处理结果**
  - **thenApply**：转换结果（同步）。
  - **thenApplyAsync**：异步转换结果。
  - **thenAccept**：消费结果，无返回值。
  - **thenRun**：任务完成后执行动作。

- **错误处理**
  - **exceptionally**：捕获异常并返回默认值。
  - **handle**：无论成功或失败均处理。

- **组合多个 Future**
  - **thenCompose**：将前序结果作为输入，串联任务。
  - **thenCombine**：合并两个独立任务的结果。
  - **allOf / anyOf**：等待所有或任意任务完成。

- **超时控制（Java 9+）**
  - **orTimeout**：设置超时时间，超时抛出 `TimeoutException`。
  - **completeOnTimeout**：超时返回默认值。

###### 线程池管理

- **默认线程池**：`ForkJoinPool.commonPool()`（适用于 CPU 密集型任务）。
- **自定义线程池**：针对 I/O 密集型任务，使用定制的线程池。

## 第四章 任务执行

#### Executor框架与线程池（ThreadPoolExecutor）

######  Executor框架的组成

| **组件**                       | **作用**                                                     |
| :----------------------------- | :----------------------------------------------------------- |
| **`Executor`**                 | 基础接口，仅定义`execute(Runnable)`方法，用于执行任务。      |
| **`ExecutorService`**          | 扩展`Executor`，提供任务提交（`submit`）、线程池关闭（`shutdown`）等功能。 |
| **`ScheduledExecutorService`** | 支持定时或周期性任务调度。                                   |
| **`ThreadPoolExecutor`**       | 最常用的线程池实现类，提供高度可配置的线程池管理。           |
| **`Executors`**                | 工厂类，提供创建常见线程池的快捷方法（如`newFixedThreadPool`）。 |

###### ThreadPoolExecutor的核心机制

- **线程池的构造参数**

  ```java
  public ThreadPoolExecutor(
      int corePoolSize,          // 核心线程数
      int maximumPoolSize,       // 最大线程数
      long keepAliveTime,        // 空闲线程存活时间
      TimeUnit unit,             // 时间单位
      BlockingQueue<Runnable> workQueue,  // 任务队列
      ThreadFactory threadFactory,        // 线程工厂
      RejectedExecutionHandler handler    // 拒绝策略
  )
  ```

- **任务提交**

  - 若当前线程数 < `corePoolSize`，立即创建新线程执行任务。
  - 若线程数 ≥ `corePoolSize`，将任务放入`workQueue`等待。
  - 若队列已满且线程数 < `maximumPoolSize`，创建临时线程处理任务。
  - 若队列已满且线程数 ≥ `maximumPoolSize`，触发`RejectedExecutionHandler`拒绝任务。

- **线程回收**

  - 临时线程（超过`corePoolSize`的部分）在空闲`keepAliveTime`后被回收。
  - 核心线程默认不回收，可通过`allowCoreThreadTimeOut(true)`启用回收。

- **关键参数详解**

  | **参数**            | **作用与典型值**                                             |
  | :------------------ | :----------------------------------------------------------- |
  | **corePoolSize**    | 核心线程数（常驻线程），默认长期存活。CPU密集型任务建议设为`CPU核心数+1`。 |
  | **maximumPoolSize** | 最大线程数（含核心线程）。IO密集型任务可设较高值（如`2*CPU核心数`）。 |
  | **keepAliveTime**   | 临时线程空闲存活时间（如30秒）。                             |
  | **workQueue**       | 任务队列，具体实现：  <br />`LinkedBlockingQueue`：无界队列（需防OOM） <br />`ArrayBlockingQueue`：有界队列（需合理容量） <br />`SynchronousQueue`：直接传递队列（高吞吐） |
  | **threadFactory**   | 自定义线程创建逻辑（如命名线程、设置优先级）。               |
  | **handler**         | 拒绝策略（当队列和线程池全满时处理新任务）：<br />`AbortPolicy`（默认）：抛出`RejectedExecutionException`<br />`CallerRunsPolicy`：由提交任务的线程执行任务 <br />`DiscardPolicy`：静默丢弃任务<br />`DiscardOldestPolicy`：丢弃队列最旧任务并重试提交 |

- **CorePoolSize设置**

  - **CPU密集型任务**（如计算、压缩）：
    - 核心线程数 = CPU核心数 + 1
    - 公式：`corePoolSize = N + 1`（N为CPU核心数），避免线程竞争导致的上下文切换开销。
  - **I/O密集型任务**（如网络请求、数据库查询）：
    - 核心线程数 = CPU核心数 × 2
    - 公式：`corePoolSize = N × (1 + 平均I/O等待时间 / 平均计算时间)`，若无法精确统计，可设为 `2N`~`5N`。

###### 线程池的创建与使用

| **方法**                    | **实现类**                  | **特性**                                                     |
| :-------------------------- | :-------------------------- | :----------------------------------------------------------- |
| `newFixedThreadPool(n)`     | ThreadPoolExecutor          | 固定大小线程池，无界队列（`LinkedBlockingQueue`），核心线程数=最大线程数。 |
| `newCachedThreadPool()`     | ThreadPoolExecutor          | 可扩容线程池，最大线程数为`Integer.MAX_VALUE`，使用`SynchronousQueue`。 |
| `newSingleThreadExecutor()` | ThreadPoolExecutor          | 单线程池，任务按顺序执行，无界队列。                         |
| `newScheduledThreadPool(n)` | ScheduledThreadPoolExecutor | 支持定时任务调度。                                           |

###### ForkJoinPool

- **工作窃取（Work-Stealing）**：
  - 每个工作线程维护一个**双端队列（Deque）**，优先从队列头部获取任务执行。
  - 当线程空闲时，从其他线程的队列**尾部**窃取任务。
- **分治任务（Fork/Join 模型）**
  - **Fork**：将大任务拆分为子任务，提交到线程池。
  - **Join**：等待子任务完成并合并结果。
  - **适用场景**：归并排序、快速排序、大数组求和等。

- **ForkJoinPool**：管理所有工作线程和任务队列。

- **ForkJoinTask**：表示可分解的任务。
  - **RecursiveAction**：无返回值的任务。
  - **RecursiveTask<T>**：有返回值的任务。

- **任务分解与调度**
  - **fork()**：将子任务异步提交到当前线程的队列。
  - **join()**：阻塞等待子任务结果（内部处理任务窃取和结果合并）。
  - **优化技巧**：父任务优先处理一个子任务，减少线程切换。

- **异常处理**：**`ForkJoinTask`** 抛出异常时，在调用 `join()` 时会封装为 `ExecutionException`。

#### 任务分界与执行策略

###### 任务分界的原则

- **独立性**

  - **无共享状态**：任务之间尽量不依赖共享数据，避免同步开销。

  - **示例**：将大数组分割为多个子数组，分别计算子数组的和。

- **粒度平衡**

  - **粗粒度**：任务过少，无法充分利用多核资源。

  - **细粒度**：任务过多，线程管理开销增大。

  - **目标**：根据硬件（如CPU核心数）和任务类型（CPU/IO密集型）调整任务粒度。

- **可组合性**：支持将子任务结果合并为最终结果（如`ForkJoinPool`的`RecursiveTask`）。

###### 任务分界的方法

- **数据分片（Data Partitioning）**

  - **原理**：将数据集划分为多个子集，每个线程处理一个子集。

  - **适用场景**：批量数据处理（如统计、图像渲染）。

- **任务流水线（Pipeline）**

  - **原理**：将任务拆分为多个阶段，每个阶段由独立线程处理（类似工厂流水线）。

  - **适用场景**：多阶段处理（如日志采集 → 清洗 → 存储）。

- **递归分解（Recursive Decomposition）**

  - **原理**：将任务递归拆分为更小的子任务，直到达到阈值后顺序执行。

  - **适用场景**：分治算法（如归并排序、快速排序）。

###### 执行策略的类型与选择

- **并行处理（Parallel Processing）**

  - **核心思想**：将任务分配给多个线程同时执行，充分利用多核CPU。

  - **适用场景**：计算密集型任务（如数值计算、图像处理）。

- **异步执行（Asynchronous Execution）**

  - **核心思想**：任务提交后立即返回，通过回调或`Future`获取结果，不阻塞主线程。

  - **适用场景**：IO密集型任务（如网络请求、文件读写）。

  - **实现工具**：`CompletableFuture`（链式异步编程）、`Future` + `ExecutorService`。

- **混合策略**

  - **接收请求**：使用异步IO（如NIO）非阻塞接收连接。

  - **处理请求**：CPU密集型任务交给固定线程池，IO操作使用异步回调。

###### 执行策略的调优技巧

- **线程池配置**

  - **计算密集型**：线程数 ≈ CPU核心数（避免过多线程竞争CPU）。

  - **IO密集型**：线程数 ≈ CPU核心数 × (1 + 平均IO等待时间/计算时间)。

  - **动态调整**：根据监控指标（队列长度、活跃线程数）调整线程池参数。

- **任务队列选择**

  - **无界队列**（如`LinkedBlockingQueue`）：适合任务量不可控但需快速响应。

  - **有界队列**（如`ArrayBlockingQueue`）：避免内存溢出，需配合拒绝策略。

  - **直接传递队列**（`SynchronousQueue`）：高吞吐，要求线程池足够大。

- **拒绝策略**

  - **`AbortPolicy`**：直接抛出异常，默认策略。

  - **`CallerRunsPolicy`**：由提交任务的线程执行任务，降低提交速率。

  - **`DiscardOldestPolicy`**：丢弃队列中最旧的任务，腾出空间。

  - **自定义策略**：记录日志或持久化被拒绝的任务。

#### 任务取消的机制

###### `Future.cancel()`方法定义

```java
boolean cancel(boolean mayInterruptIfRunning);
```

- **作用**：尝试取消任务的执行。
- **参数**：`mayInterruptIfRunning`表示是否允许中断正在执行任务的线程。
- **返回值**：
  - `true`：任务成功取消（任务未启动或已启动且允许中断）。
  - `false`：任务已结束或无法取消。

###### `cancel()`的行为场景

- **任务尚未启动**：任务直接从任务队列中移除，不会执行。

- **任务正在运行**：根据**`mayInterruptIfRunning`**参数决定是否中断任务线程：

  - **`mayInterruptIfRunning=true`**：向任务线程发送中断信号（设置中断标志位）。

  - **`mayInterruptIfRunning=false`**：不中断线程，任务继续执行，但若任务未开始则取消。

- **任务已完成或已取消**：调用`cancel()`返回`false`，无实际效果。

###### 任务如何响应取消

- **协作式中断**：任务的取消需要**协作**，即任务必须主动检查中断状态或处理中断异常。
  - **检查中断标志**：在循环或耗时操作中定期调用`Thread.interrupted()`。
  - **处理`InterruptedException`**：在阻塞操作（如`Thread.sleep()`、`wait()`）中捕获异常并退出。

###### 与其他机制对比

| **机制**              | **原理**                   | **优点**                 | **缺点**                     |
| :-------------------- | :------------------------- | :----------------------- | :--------------------------- |
| **`Future.cancel()`** | 基于中断标志的协作式取消   | 标准化，与线程池集成方便 | 依赖任务协作，无法强制终止   |
| **自定义标志位**      | 通过`volatile boolean`控制 | 灵活，无中断依赖         | 需手动检查，无法中断阻塞操作 |
| **`Thread.stop()`**   | 强制终止线程（已废弃）     | 立即停止任务             | 不安全，易导致数据不一致     |

## 第五章 避免活跃性危险

#### 死锁（Deadlock）的产生条件与避免策略

###### 死锁的定义

- **死锁（Deadlock）** 是指两个或多个线程在执行过程中，因争夺资源而陷入相互等待的状态，导致所有线程无法继续执行。
  - **线程A** 持有锁1并请求锁2。
  - **线程B** 持有锁2并请求锁1。

###### 死锁的四个必要条件

- **互斥条件（Mutual Exclusion）**：资源一次只能被一个线程独占使用（如锁、文件句柄）。
  - **示例**： 两个线程无法同时写入同一个文件。
- **持有并等待（Hold and Wait）**：线程在持有至少一个资源的同时，请求其他线程持有的资源。
  - **示例**： 线程A拿着锁1去申请锁2，线程B拿着锁2去申请锁1。
- **不可抢占（No Preemption）**：资源只能由持有者主动释放，不能被强制抢占。
  - **示例**： 无法强行终止持有锁的线程以释放资源。
- **循环等待（Circular Wait）**：存在一个线程等待环路，每个线程都在等待下一个线程持有的资源。
  - **示例**： 线程A→等B→等C→等A，形成环状依赖。

###### 避免死锁的策略

- ##### **破坏循环等待：锁顺序化（Lock Ordering）**

  - **原理**：所有线程按全局固定的顺序获取锁，消除循环等待。
  - **示例**：转账时按账户ID顺序加锁。

- **破坏持有并等待：一次性申请所有资源**

  - **原理**：线程在开始执行前，一次性申请所需全部资源。
  - **示例**：使用`tryLock`尝试获取所有锁，失败则释放已持有的锁。

- **破坏不可抢占：允许资源抢占**

  - **原理**：设计超时机制，超时后释放资源并重试。
  - **示例**：使用带超时的`tryLock`。

- **破坏互斥条件：减少资源独占**

  - **原理**：使用无锁数据结构（如`ConcurrentHashMap`）或共享资源。
  - **示例**：用原子变量替代锁。

#### 活锁（Livelock）与饥饿（Starvation）问题

###### 活锁（Livelock）

- 活锁是线程**未被阻塞但无法继续执行**的状态，因为线程不断重复执行某个操作（如重试或回退），导致系统整体无进展。

- ##### **产生原因**

  - **过度协作**：线程间过度响应彼此状态变化，导致无限循环。
  - **重试机制设计不当**：例如退避算法（Exponential Backoff）未引入随机性。

- ##### **解决策略**

  - **引入随机性**：在重试逻辑中加入随机等待时间（如指数退避）。
  - **协调机制**：由第三方统一调度资源分配，避免线程自发决策。

###### 饥饿（Starvation）

- **定义**：饥饿指某个线程**长期无法获取所需资源**（如CPU时间片、锁、IO等），导致任务无法执行。

- ##### **产生原因**

  - **资源分配策略不公平**：例如线程优先级设置不合理。
  - **锁竞争策略缺陷**：如非公平锁导致某些线程长期无法获取锁。

- #####  **解决策略**

  - **公平调度**：使用公平锁（`ReentrantLock(true)`）或公平队列。
  - **避免优先级滥用**：谨慎设置线程优先级，依赖操作系统的默认调度。
  - **资源配额管理**：为线程分配最大执行时间或资源上限（如令牌桶算法）。

###### 活锁与饥饿的对比

| **特性**     | **活锁（Livelock）**     | **饥饿（Starvation）**         |
| :----------- | :----------------------- | :----------------------------- |
| **线程状态** | 线程仍在运行，但无法推进 | 线程被阻塞或等待，无法获取资源 |
| **原因**     | 过度协作或错误的重试逻辑 | 资源分配不公平或优先级失衡     |
| **解决重点** | 打破循环依赖，引入随机性 | 实现公平的资源分配机制         |

## 第六章 性能与可伸缩性

#### 减少锁竞争

###### 缩小同步块（Lock Narrowing）

- **原理**：仅在访问共享资源的**最小必要代码段**上加锁，减少线程持有锁的时间，降低竞争概率。

- ##### **注意事项**

  - **锁粒度**：过细的锁可能导致频繁获取/释放，增加开销。
  - **数据一致性**：确保同步块覆盖所有必要的共享数据操作。

###### 锁分离（Lock Splitting）

- **原理**：将一个大锁拆分为多个细粒度锁，分别保护不同的资源或操作，降低锁的竞争频率。
- **读写锁分离（ReadWriteLock）**
  - **读锁**：允许多线程并发读。
  - **写锁**：独占写，阻塞读写操作。
- **数据结构锁分离（如ConcurrentHashMap）**
  - **JDK 7的分段锁**：将哈希表分为多个段（Segment），每个段独立加锁。
  - **JDK 8的CAS + synchronized**：每个桶（Node）独立加锁，进一步细化粒度。

###### 无锁数据结构（Lock-Free Data Structures）

- **原理**：通过**原子操作（CAS）**实现线程安全，完全避免传统锁机制，减少上下文切换和阻塞。
- **实现方法**：原子类（Atomic Classes）、CAS自旋（Compare-And-Swap）、并发容器（如ConcurrentLinkedQueue）

###### 策略对比与适用场景

| **策略**         | **适用场景**                   | **优点**           | **缺点**                 |
| :--------------- | :----------------------------- | :----------------- | :----------------------- |
| **缩小同步块**   | 同步代码中存在非共享操作       | 简单易行，快速生效 | 需精确识别临界区，易遗漏 |
| **锁分离**       | 资源可分类（如读写分离）       | 显著提升并发度     | 增加锁管理复杂度         |
| **无锁数据结构** | 高竞争、低延迟场景（如计数器） | 无阻塞，极致性能   | 实现复杂，需处理ABA问题  |

#### 性能优化指标

###### 吞吐量（Throughput）

- **定义**：**吞吐量**指系统在**单位时间内**处理的任务数量或数据量。

- ##### **优化场景**

  - **批处理系统**：如日志分析、数据导入导出。
  - **高并发服务**：如电商秒杀、API网关。

- ##### **优化策略**

  - **减少锁竞争**：使用细粒度锁、无锁数据结构（如`ConcurrentHashMap`）。
  - **提升资源利用率**：合理配置线程池大小，避免CPU空闲或过载。
  - **批处理操作**：合并IO操作（如批量写入数据库）。

###### 延迟（Latency）

- **定义**：**延迟**指单个任务从**提交到完成**所需的时间。

- ##### **优化场景**

  - **实时系统**：如高频交易、在线游戏。
  - **用户交互服务**：如网页加载、API响应。

- **优化策略**

  - **减少任务排队**：使用无界队列或直接传递队列（如`SynchronousQueue`）。
  - **异步处理**：将非关键路径操作异步化（如日志记录）。
  - **缓存优化**：缓存热点数据，减少计算或IO时间。

###### 可伸缩性（Scalability）

- **定义**：**可伸缩性**指系统通过**增加资源**（如CPU、节点）提升吞吐量或降低延迟的能力。

- **水平扩展**：增加节点（如分布式系统）。

- **垂直扩展**：提升单节点资源（如CPU、内存）。

- ##### **优化场景**

  - **云计算环境**：动态扩缩容应对流量波动。
  - **分布式系统**：如微服务集群、数据库分片。

- ##### **优化策略**

  - **无状态设计**：方便水平扩展（如RESTful服务）。
  - **分片（Sharding）**：将数据拆分到多个节点（如数据库分库分表）。
  - **避免单点瓶颈**：如使用分布式缓存（Redis Cluster）替代单机缓存。

###### 指标间的权衡与平衡

| **场景**         | **优先指标** | **策略示例**                     | **潜在代价**   |
| :--------------- | :----------- | :------------------------------- | :------------- |
| **电商大促**     | 吞吐量       | 增加线程池大小，批量处理订单     | 可能增加延迟   |
| **实时风控系统** | 延迟（P99）  | 使用低延迟数据结构，减少同步操作 | 可能降低吞吐量 |
| **社交平台扩展** | 可伸缩性     | 数据库分片，无状态服务设计       | 系统复杂度增加 |

#### 非阻塞算法

###### 非阻塞算法的核心思想

- 非阻塞算法通过**原子操作**（如CAS）实现线程安全，避免使用传统锁机制，从而消除锁带来的性能瓶颈（如上下文切换、死锁）。
- **无锁（Lock-Free）**：至少有一个线程能持续前进。
- **无等待（Wait-Free）**：所有线程都能在有限步骤内完成操作。

###### CAS（Compare-and-Swap）操作

- CAS是一种原子指令，用于在多线程环境下实现无锁同步。

  ```java
  boolean compareAndSwap(Variable V, ExpectedValue A, NewValue B) {
      if (V == A) {
          V = B;
          return true;
      }
      return false;
  }
  ```

- Java通过`Unsafe`类提供CAS操作，但开发者通常使用封装好的原子类（如`AtomicInteger`）

  ```java
  AtomicInteger counter = new AtomicInteger(0);
  counter.compareAndSet(0, 1); // 若当前值为0，则更新为1
  ```

- 非阻塞数据结构：无锁栈（Treiber Stack）、无锁队列（Michael-Scott队列）

###### CAS与锁的对比

| **场景**         | **CAS**                   | **锁（如synchronized）** |
| :--------------- | :------------------------ | :----------------------- |
| **低/中竞争**    | 性能更优，无阻塞          | 上下文切换开销大         |
| **高竞争**       | 自旋导致CPU浪费           | 线程阻塞减少CPU占用      |
| **实现复杂度**   | 高（需处理ABA、重试逻辑） | 低（直接加锁）           |
| **适用数据结构** | 简单结构（计数器、队列）  | 复杂结构（需精细锁控制） |

## 第七章 显式锁

#### ReentrantLock 与 synchronized 对比详解

###### 核心特性对比

| **特性**                  | **ReentrantLock**                           | **synchronized**                        |
| :------------------------ | :------------------------------------------ | :-------------------------------------- |
| **锁的获取方式**          | 手动`lock()`和`unlock()`，需在`finally`释放 | 自动获取与释放（代码块或方法退出时）    |
| **可中断性**              | 支持（`lockInterruptibly()`）               | 不支持，线程阻塞时无法中断              |
| **公平性**                | 可配置公平或非公平锁（默认非公平）          | 仅非公平锁                              |
| **条件变量（Condition）** | 支持多个条件队列                            | 通过`wait()`/`notify()`实现单一等待队列 |
| **超时机制**              | 支持`tryLock(timeout, unit)`                | 不支持，无法设置超时                    |
| **性能**                  | 高竞争场景下更优（JDK 5~6）                 | JDK 6+优化后性能接近，低竞争场景更轻量  |
| **锁绑定多个条件**        | 是                                          | 否                                      |

###### 核心差异详解

- **锁的获取与释放**

  - **ReentrantLock**：必须手动调用`lock()`和`unlock()`，通常在`try-finally`中确保释放【显式管理】。
  - **synchronized**：进入同步代码块自动获取锁，退出时自动释放（包括正常返回或异常抛出）【隐式管理】。

- **可中断性**

  - **ReentrantLock**：线程在等待锁时可响应中断（通过`lockInterruptibly()`）。
  - **synchronized**：线程在等待锁时无法被中断，只能一直阻塞。

- **公平性**

  - **ReentrantLock公平锁**：按请求顺序分配锁，避免线程饥饿（构造时传入`true`）。
  - **ReentrantLock非公平锁**：允许插队（默认模式，吞吐量更高）。

  - **synchronized**：仅支持非公平锁，无法配置公平性。

- **条件变量**
  - **ReentrantLock**：支持多个`Condition`，实现精细的线程等待与唤醒。
  - **synchronized**：单一等待队列，通过`wait()`和`notifyAll()`实现，灵活性较差。
- **超时机制**
  - **ReentrantLock**：支持尝试获取锁（`tryLock()`）或带超时获取（`tryLock(timeout, unit)`）。
  - **synchronized**：无超时机制，线程可能永久阻塞。

###### 性能对比与选择建议

| **场景**             | **推荐选择**           | **理由**                                                 |
| :------------------- | :--------------------- | :------------------------------------------------------- |
| **简单同步需求**     | `synchronized`         | 代码简洁，自动管理锁，JDK 6+性能优化后足够高效。         |
| **高竞争、复杂逻辑** | `ReentrantLock`        | 支持可中断、超时、公平锁和条件变量，灵活应对复杂场景。   |
| **需要多个条件变量** | `ReentrantLock`        | 通过多个`Condition`实现精细控制（如生产者-消费者模型）。 |
| **避免死锁**         | `ReentrantLock` + 超时 | 超时机制可主动退出阻塞，降低死锁风险。                   |

#### 公平锁与非公平锁的选择

###### 公平锁与非公平锁的定义

- **公平锁（Fair Lock）**：线程按照请求锁的**绝对顺序**获取锁（先到先得）。
- **非公平锁（Non-Fair Lock）**：允许新请求的线程**插队**竞争锁，可能先于等待队列中的线程获得锁。

###### 实现机制

- **ReentrantLock公平锁**：当锁可用时优先检查等待队列中是否有线程在等待，若有唤醒队列头部线程；否则允许当前线程获取锁。
- **ReentrantLock非公平锁**：直接尝试通过CAS获取锁，失败后再加入等待队列，新线程可随时插队。

###### 性能对比

| **场景**         | **公平锁**               | **非公平锁**                         |
| :--------------- | :----------------------- | :----------------------------------- |
| **低竞争环境**   | 线程切换频繁，吞吐量较低 | 减少线程切换，吞吐量更高             |
| **高竞争环境**   | 避免饥饿，但吞吐量下降   | 允许插队，减少上下文切换，吞吐量更优 |
| **线程饥饿风险** | 无                       | 可能存在（长时间等待的线程无法获锁） |

#### 读写锁（ReentrantReadWriteLock）的应用场景

###### 读写锁的核心特性

- **读锁（共享锁）**：允许多个线程同时持有，用于并发读取共享资源。
- **写锁（独占锁）**：同一时刻仅允许一个线程持有，用于修改共享资源，阻塞其他所有读写操作。

###### 适用场景

- ##### **读多写少的数据结构**

  - **场景**：数据被频繁读取，但写入操作较少。
  - **示例**：缓存系统、配置管理、元数据访问。
  - **优势**：读操作并发执行，大幅提升吞吐量。

- ##### **资源池管理**

  - **场景**：资源池（如数据库连接池）需高频借用（读）和低频扩容/缩容（写）。
  - **示例**：线程安全地管理连接池资源。
  - **优势**：资源获取（读锁）可并发执行，资源变更（写锁）保证原子性。

- ##### **数据副本同步**

  - **场景**：主从数据副本，主数据更新后同步到从副本。
  - **示例**：主数据写入需独占锁，副本读取可共享。
  - **优势**：写入时阻塞所有操作保证一致性，读取时允许多线程并发。

- ##### **高并发统计计数**

  - **场景**：高频读取统计数据，低频更新统计值。
  - **示例**：网站访问量统计。

###### 与其他并发工具的对比

| **场景**               | **推荐工具**           | **理由**                                            |
| :--------------------- | :--------------------- | :-------------------------------------------------- |
| **读多写少，允许脏读** | `StampedLock`          | 乐观读模式（`tryOptimisticRead()`）无锁，性能更高。 |
| **读多写少，简单结构** | `CopyOnWriteArrayList` | 写时复制，读完全无锁，但写开销大。                  |
| **写多读少**           | `ReentrantLock`        | 直接使用独占锁更简单高效。                          |