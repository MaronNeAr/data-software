#### 第1章 综述

###### 大数据体系架构图

<img src="https://p.ipic.vip/td9bk3.png" alt="image-20250720142609324" style="zoom:50%;" />

###### 数据采集层

- **Aplus.JS**：Web端日志采集技术方案。
- **UserTrack**： APP端日志采集技术方案。
- **TimeTunnel**：DB增量数据传输及日志数据传输，支持流式计算和基于时间窗口的批量计算。
- **DataX**：阿里数据同步工具，直连异构数据库来抽取各种时间窗口的数据。

###### 数据计算层

- **MaxCompute**：离线大数据存储及计算平台。
- **StreamCompute**：实时大数据存储及流式计算平台。
- **OneData**：数据整合及管理（如指标体系和数据服务）的方法体系和工具，包含OneID、OneMetric和OneService。
- **离线数仓**：数据计算主要以天为单位（包含小时、周、月），每日凌晨处理T-1的数据。
- **实时数仓**：实时计算更新数据，如实时数据大屏。
- **数仓分层**
  - 操作数据层（ Operational Data Store, ODS） 
  - 明细数据层（ Data Warehouse Detail , DWD ）
  - 汇总数据层（ Data Warehouse Summary, DWS ）
  - 应用数据层（ Application Data Store, ADS ）
- **元数据管理**：数据源元数据、数据仓库元数据 、数据链路元数据、工具类类元数据、数据质量类元数据。
- **元数据应用**：主要面向数据发现、数据管理等 ，如用于存储、计算和成本管理等。

###### 数据服务层

- **OneService**：统一数据服务平台，以数据仓库整合计算好的数据作为数据源，对外通过接口的方式提供数据服务。
- **功能**：提供简单数据查询服务、复杂数据查询服务和实时数据推送服务。

## 第一篇 数据技术篇

#### 第2章 日志采集

###### 浏览器的页面日志采集

- **基础指标**：页面浏览量（ Page View, PV）和访客数（ Unique Visitors, UV ）。
- **页面浏览日志采集流程**
  - **客户端日志采集**：由植入HTML页面的JS脚本来执行，采集脚本被浏览器加载解析后执行。
  - **客户端日志发送**：采集脚本执行时，会向日志服务器发起一个日志请求，以将采集到的数据发送到日志服务器。
  - **服务端日志收集**：服务器接受客户端日志请求后，放入日志缓冲区。
  - **服务端日志解析**：日志处理程序会对日志缓冲区顺序读取并进行处理解析。
- **页面交互日志采集**
  - **步骤一**：业务方在日志服务的元数据管理界面依次注册需要采集交互日志的业务、业务场景和具体的交互采集点。
  - **步骤二**：业务方将交互日志采集代码植入目标页面，并将采集代码与需要检测的用户行为相绑定。
  - **步骤三**：当用户在页面上产生指定行为时，采集代码和正常的业务互动响应代码一起被触发和执行。
  - **步骤四**：采集请求到服务端后，不做解析处理，只做简单的转储。
- **页面日志的服务端清洗和预处理**：识别流量攻击、网络爬虫和流量作弊、数据缺项补正、无效数据剔除、日志隔离分发。

###### APP端的日志采集

- **UserTrack**：利用采集SDK来进行APP端的日志采集。
- **事件类型**：页面事件（页面浏览）和控件点击事件（页面交互）等。
- **页面事件**
  - **日志记录**：①设备及用户的基本信息；②被访问页面的信息及业务参数 ; ③访问基本路径（如页面来源、 来源的来源 ）。
  - **手动埋点**：UserTrack提供三个接口（展现、退出、扩展），分别在页面展现、页面退出时调用记录用户操作信息。
  - **SPM（Super Position Model）**：越级位置模型，可以进行来源去向追踪，通过透传机制还原用户行为路径。
- **控件点击**：①设备信息；②用户信息；③控件所在页面；④控件名称；⑤控件业务参数。
- **其他事件**：①事件名称；②事件时长；③事件所携带的属性；④事件对应的页面。
- **H5&Native日志统一**
  - **步骤一**：H5页面手动植入日志采集的JS脚本。
  - **步骤二**：JS脚本执行时将所采集的数据打包到一个对象，利用WebView的JSBridge进行通信存储到客户端。
  - **步骤三**：移动客户端日志采集 SDK ，封装提供接口，实现将传入的内容转换成移动客户端日志格式。
- **日志传输**：APP端产生日志后先存储在本地，然后伺机上传到服务器，服务端对不同等级的日志需要进行分流。

###### 日志采集的挑战

- **日志分流及定制处理**：日志解析和处理过程中必须考虑业务分流、日志优先级控制，以及根据业务特点实现定制处理。
- **采集与计算一体化设计**
  - **背景**：超大规模日志进行URL分流，使用正则匹配计算时会拖垮整个硬件计算集群。
  - **方案**：通过 SPM 的注册和简单部署即可将任意的页面流量进行聚类得到聚合数据，避免服务端计算。

#### 第3章 数据同步

###### 数据同步基础

- **直连同步**：通过定义好的规范接口API和基于动态链接库的方式直接连接业务数据库，如ODBC/JDBC。
  - **痛点**：执行大量数据同步时会降低甚至拖垮业务系统的性能。
- **数据文件同步**：直接从源系统生成数据的文本文件，由文件服务器传输到目标系统后，加载到目标数据库系统中（如日志同步）。
- **数据库日志解析同步**：以通过源系统的进程，读取归档日志文件用以收集变化的数据信息，将其解析到目标数据文件中。
  - **痛点**：大量数据同步导致数据延迟、数据漂移和遗漏。

###### 阿里数据仓库的同步方式

- **批量数据同步**：多源数据 ➡️ 数据仓库；数据仓库 ➡️ 业务系统。
  - **DataX**：能满足多方向高自由度的异构数据交换服务产品。
  - **Framework + Plugin**： Framework处理缓冲、流程控制、并发、上下文加载。
  - **Job**：数据同步作业。
  - **Splitter**：作业切分模块，将1个大任务分解成多个可以并发行的小任务。
  - **Task**：数据同步作业切分后的小任务。
  - **Reader**：数据读入模块，负责运行切分后的小任务，将数据从源系统装载到 DataX。
  - **Channel**： Reader 和 Writer 通过 Channel 交换数据。
  - **Writer**：数据写出模块，负责将数据从 DataX 导入目标数据系统。
- **实时数据同步**：日志需要快速以数据流的方式不间断地同步到数据仓库。
  - **TimeTunnel**：是一种基于生产者、消费者和 Topic 消息标识的消息中间件，将消息数据持久化到 HBase 的数据交互系统。
  - **生产者**：消息数据的产生端，向 TimeTunnel 集群发送消息数据。
  - **消费者**：消息数据的接收端，从 TimeTunnel 集群中获取数据进行业务处理。
  - **Topic**：消息类型的标识。
  - **Broker**： 负责处理客户端收发消息数据的请求，然后往 HBase 取发数据。

###### 数据同步遇到的问题与解决方案

- **分库分表处理**：通过建立中间状态的逻辑表来整合统一分库分表的访问，如TDDL数据访问引擎。

- **TDDL**：实现了 SQL 解析、规则计算、表名替换、选择执行单元并合并结果集的功能。

  <div>
    <span>
      <img src="https://p.ipic.vip/znb4x7.png" alt="image-20250719151404494" style="zoom: 36%;" align="left" />
    </span>
    <span>
      <img src="https://p.ipic.vip/nyvyxf.png" alt="image-20250719151830009" style="zoom:44%;" align="right"/>
    </span>
  </div>





















- **高效同步和批量同步**
  - **痛点**：大量重复的数据任务操作、数据源种类太多需要特殊配置。
  - **OneClick**：对不同数据源同步配置透明化，自动生成配置信息；简化步骤，建表、配置任务、发布、测试操作一键化处理。
  - **IDB**：集数据管理、结构管理、诊断优化、实时监控和系统监控于一体的数据管理服务。
- **增量与全量同步的合并**
  - **增量同步**：每次只同步新变更的增量数据到目标系统。
  - **全量同步**：每次同步数据源数据表的所有数据到目标系统。
  - **合并技术**：全外连接（full outer join） + 数据全量覆盖重新加载（insert overwrite）（全量更新比update性能高很多）。
  - **分区技术**：每日调度最新的数据到新的分区，和原来所有分区的数据组成全量数据
- **同步性能处理**
  - **痛点**：部分同步任务分发到CPU比较繁忙的机器会拖垮数据同步性能；数据同步任务无优先级，导致重要同步任务得不到调度。
  - **计算量级**：估算该同步任务需要同步的数据量、平均同步速度、首轮运行期望的线程数、需要同步的总线程数。
  - **数据分发**：根据同步的总线程数将待同步的数据拆分成相等数量的数据块，一个线程处理个数据块。
  - **同步控制**：同步控制器判断待同步的总线程数是否大于首轮运行期望的线程数，大于则跳转至多机处理；否则跳转至单机处理。
  - **多机处理**：准备该任务第一轮线程的调度，优先发送等待时间最长、优先级最高且同步任务的线程。
  - **单机处理**：优先发送等待时间最长、优先级最高且单机 CPU 剩余资源可以支持首轮所有线程数且同任务的线程，如果没有满足条件的机器，则选择 CPU 剩余资源最多的机器进行首轮发送。
- **数据漂移处理**：通常是指 ODS 表的同一个业务日期数据中包含前一天或后凌晨附近的数据或者丢失当天的变更数据。
  - **时间戳字段**：modified_time数据表更新时间；log_time 数据日志更新时间；proc_time数据表业务发生时间；extract_time数据抽取时间。
  - **漂移场景**：数据抽取时间extract_time有延迟；业务系统未更新modified_time；系统压力导致log_time、modified_time延迟。
  - **处理方法**：多获取后一天的数据，业务根据延迟时间确定；通过多个时间戳字段获得相对精确的值。

#### 第4章 离线数据开发

###### 数据开发平台

- **统一计算平台**

  - **MaxCompute**：主要服务于海量数据的存储和计算 ，提供完善的数据导入方案， 以及多种经典的分布式计算模型，提供海量数据仓库的解决方案，能够更快速地解决用户的海量数据计算问题，有效降低企业成本，并保障数据安全。

  - **MaxCompute客户端**：包括Web、SDK、CLT、IDE等形式完成 Project 管理、数据同步、任务调度、报表生成等常见操作。

  - **MaxCompute接入层**：提供HTTP服务、Cache、负载均衡，实现用户认证和服务层面的访问控制。

  - **MaxCompute控制层**：实现用户空间和对象的管理、命令的解析与执行逻辑、数据对象的访问控制与授权等功能。

    > **Worker**：处理所有的RESTful 请求，包括用户空间（ Project ）管理操作、资源（ Resource） 管理操作、作业管理等；对于 SQL DML、MR 等需要启动 MapReduce 的作业，会生成 MaxCompute Instance 提交给 Scheduler 一步处理。
    >
    > **Scheduler**：负责MaxCompute Instance的调度和拆解，并向计算层的计算集群询问资源占用情况以进行流控。
    >
    > **Executor**：负责 MaxCompute Instance 的执行，向计算层的计算集群提交真正的计算任务。

  - **MaxCompute计算层**：包括分布式文件系统（Pangu）、资源调度系统（Fuxi）、NameSpace服务、监控模块。

  - **MaxCompute元数据**：主要包括用户空间元数据、 Table Partition Schema、ACL、Job 元数据、安全体系等。

  - **MaxCompute架构**

    <img src="https://p.ipic.vip/youomw.png" alt="image-20250720144935336" style="zoom:50%;" />

- **统一开放平台**

  - **D2**：集成任务开发、调试及发布，生产任务调度及大数据运维，数据权限申请及管理等功能的一站式数据开发平台。

  - **Dataworks**：核心功能与D2一致，D2服务与阿里集团内部业务，Dataworks则为阿里云对外商业化大数据开发治理平台。

  - **SQLSCAN**：在任务开发中用户编写的SQL质量差、性能低、不遵守规范等问题，总结成规范，通过系统及研发流程保障。

    >**代码规范类规则**：表命名规范、生命周期设置、表注释等。
    >
    >**代码质量类规则**：调度参数使用检查、分母为0提醒、 NULL 值参与计算影响结果提醒、插入字段顺序错误等。
    >
    >**代码性能类规则**：分区裁剪失效、扫描大表提醒、重复计算检测等。

  - **DQC**：主要关注数据质量， 通过配置数据质量校验规则，自动在数据处理任务过程中进行数据质量方面的监控。

    > **数据监控**：监控数据质量并报警，其本身不对数据产出进行处理，需要报警接收人判断并决定如何处理。
    >
    > **数据清洗**：将不符合既定规则的数据清洗掉，以保证最终数据产出不含“脏数据”，数据清洗不会触发报警。
    >
    > **监控规则**：主键监控、表数据量及波动监控、重要字段的非空监控、重要枚举宇段的离散值监控、 指标值波动监控等。

###### 任务调度系统

- **核心设计模型**

  - **调度引擎**：根据任务节点属性及依赖关系进行实例化， 生成各类参数的实值，并生成调度树。
  - **执行引擎**：根据调度引擎生成的具体任务实例和配置信息，分配 CPU 内存、运行节点等资源，在任务对应的环境中运行代码。

- **任务状态机模型**

  - **预备阶段**：WAITING_DEPENDENCY → READY → WAITING_RESOURCE
  - **执行阶段**：RUNNING（核心处理节点）
  - **终态阶段**：SUCCESS/KILLED/SUSPENDED
  - **异常回路**：FAILED ⇄ WAITING_RETRY

  ```mermaid
  stateDiagram-v2
  		direction LR
      [*] --> WAITING_DEPENDENCY : 任务创建
      WAITING_DEPENDENCY --> READY : 上游依赖满足
      READY --> WAITING_RESOURCE : 提交执行请求
      WAITING_RESOURCE --> RUNNING : 资源分配完成
      RUNNING --> SUCCESS : 执行成功
      RUNNING --> FAILED : 执行异常
      RUNNING --> KILLING : 用户主动终止
      FAILED --> WAITING_RETRY : 重试次数未耗尽
      WAITING_RETRY --> READY : 到达重试时间
      FAILED --> SUSPENDED : 重试次数耗尽
      KILLING --> KILLED : 终止完成
      SUCCESS --> [*] : 生命周期结束
      KILLED --> [*] : 生命周期结束
      SUSPENDED --> READY : 人工干预恢复
      SUSPENDED --> [*] : 人工确认终止
  
      note right of WAITING_DEPENDENCY
          核心依赖检查：
          1. 父任务状态（成功/跳过）
          2. 跨周期依赖满足
          3. 数据分区就绪
          4. 业务日期有效性
      end note
  
      note left of RUNNING
          执行引擎交互：
          - 启动计算引擎（MaxCompute/Hive/Spark）
          - 实时监控资源水位
          - 进度心跳检测（超时自动失败）
          - 日志实时采集
      end note
  
      note right of WAITING_RETRY
          智能重试策略：
          1. 指数退避时间（5s→10s→30s→1m）
          2. 资源不足时自动扩容
          3. 节点故障自动转移
          4. 环境异常自动隔离
      end note
  ```

- **工作流状态机模型**

  ```mermaid
  stateDiagram-v2
      direction LR
      [*] --> NOT_STARTED : 工作流创建
      NOT_STARTED --> RUNNING : 调度时间到达
      RUNNING --> RUNNING : 子任务执行中
      RUNNING --> SUCCESS : 所有子任务成功
      RUNNING --> FAILED : 关键子任务失败
      RUNNING --> SUSPENDED : 人工暂停
      RUNNING --> KILLING : 人工终止
      SUSPENDED --> RUNNING : 人工恢复
      SUSPENDED --> KILLING : 人工终止
      FAILED --> RUNNING : 人工重跑
      FAILED --> KILLING : 人工终止
      KILLING --> KILLED : 终止完成
      SUCCESS --> [*] : 生命周期结束
      KILLED --> [*] : 生命周期结束
  
      note left of NOT_STARTED
          启动前检查：
          1. 上游工作流状态
          2. 业务周期有效性
          3. 全局资源水位
          4. 调度配额
      end note
  
      note right of RUNNING
          工作流执行控制：
          - 任务并行度控制
          - 优先级动态调整
          - 子任务状态聚合
          - 关键路径监控
          - 自动容错（子任务重试）
      end note
  
      note left of SUSPENDED
          暂停状态行为：
          1. 冻结所有子任务状态
          2. 保留当前执行快照
          3. 释放非关键资源
          4. 通知下游工作流
      end note
  
      note right of KILLING
          终止过程：
          1. 发送终止信号到所有子任务
          2. 清理中间数据
          3. 释放所有资源
          4. 更新血缘关系状态
      end note
  ```

- **调度引擎工作原理**

  - **Async Dispatcher**：异步处理任务调度。
  - **Sync Dispatcher**：同步处理任务调度。
  - **Task 事件处理器**：任务事件处理器，与任务状态机交互。
  - **DAG 事件处理器**：工作流事件处理器，与工作流状态机交互，一个DAG 事件处理器包含若干个 Task 事件处理器。

- **执行引擎工作原理**
  - **任务管理接口**：供用户系统向 Alisa 中提交、查询和操作离线任 务，并获得异步通知。
  - **系统管理接口**：供系统管理员进行后台管理，包括为集群增加新 的机器、划分资源组、查看集群资源和负载、追踪任务状态等。
  - **Driver**：中实现了任务管理接口和系统管理接口；负责任务的调度策略、集群容灾和伸缩、任务失效备援、 负载均衡实现。
  - **Task pool**：已经提交的任务放入到 Task pool 中管理，包括等待资源、数据质量检测、运行中、运行成功和失败的所有任务。
  - **Resource manager**：组件专注于集群整体资源的管理。
  - **Task container**：容器负责处理 Task 的公共逻辑，如文件下载，任务级 Session 、流程级 Session 的维护等。
  - **Session manager** ：组件实现了对 Task session 的管理。
  - **Node**：Node节点负责提供任务运行所需的物理资源，Node 是逻辑概念， 一台物理机器上可部署一个或者多个 Node。

<div>
  <span>
		<img src="https://p.ipic.vip/hdjev3.png" alt="image-20250720141612336" style="zoom:34%;" />
  </span>
  <span>
    <img src="https://p.ipic.vip/7p1ura.png" alt="image-20250720141634721" style="zoom:34%;" />
  </span>
</div>

- **任务调度系统应用**
  - **调度配置**：任务提交时， SQL 解析引擎自动识别此任务的输入表和输出 表，输入表自动关联产出此表的任务 ，输出表亦然。
  - **定时调度**：可以根据实际需要，设定任务的运行时间，共有5种时间类型：分钟、小时、日、周、月，具体可精确到秒。
  - **周期调度**：可按照小时、日等时间周期运行任务，与定时调度的区别是无须指定具体的开始运行时间。
  - **手动运行**：当生产环境数据修复或临时数据操作时，在开发环境中写好脚本后发布到生产环境，再通过手动触发运行。
  - **基线管理**：基于充分利用计算资源，保证重点业务数据优先产出，合理安排各类优先级任务的运行。

#### 第5章 实时技术

###### 简介



###### 流式技术架构



###### 流式数据模型



#### 第6章 数据服务

###### 服务架构演进



###### 技术架构



###### 最佳实践



#### 第7章 数据挖掘

###### 数据挖掘概述



###### 数据挖掘算法平台



###### 数据挖掘中台体系



###### 数据挖掘案例



## 第二篇 数据模型篇

#### 第8章 大数据领域建模综述

###### 为什么需要数据建模



###### 关系数据库系统和数据仓库



######  OLTP和OLAP 系统的区别看模型方法论的选择



###### 典型的数据仓库建模方法论



###### 阿里巴巴数据模型实践综述



#### 第9章 阿里巴巴数据整合及管理体系

###### 概述



###### 规范定义



###### 模型设计



###### 模型实施



#### 第10章 维度设计

###### 维度设计基础



###### 维度设计高级基础



###### 维度变化



###### 特殊维度



#### 第11章 事实表设计

###### 事实表基础



###### 事务事实表



###### 周期快照事实表



###### 累积快照事实表

###### 

###### 三种事实表的比较



###### 聚集型事实表



## 第三章 数据管理篇

#### 第12章 元数据

###### 元数据概述



###### 元数据应用



#### 第13章 计算管理

###### 系统优化



###### 任务优化



#### 第14章 存储和成本管理

###### 数据压缩



###### 数据重分布



###### 存储治理项优化



###### 生命周期管理



###### 数据成本计量



###### 数据使用计费



#### 第15章 数据质量

###### 数据质量保障原则



###### 数据质量方法概述



## 第四篇 数据应用篇

#### 第16章 数据应用

###### 生意参谋



###### 数据产品平台













