## 第一章 引言与概述

#### 数据库系统的分层架构

###### 用户接口层

- 用户通过SQL、API（如JDBC/ODBC）或图形界面与数据库交互。
- 示例：用户提交的查询语句（如 `SELECT * FROM Employees`）。

###### 查询处理器层

- **查询解析与优化**：将SQL语句转换为逻辑查询计划（如关系代数表达式），再优化为物理执行计划（如选择索引扫描或全表扫描）。
- **执行引擎**：根据优化后的计划调用存储管理器的接口获取数据。

###### 存储管理器层

- **文件与索引管理**：负责数据的物理存储（如B+树索引、哈希文件）。
- **缓冲区管理**：协调内存与磁盘的数据交换，减少I/O开销（如LRU缓存策略）。
- **事务管理**：通过日志和锁机制保障事务的ACID特性。

###### 磁盘存储层

- 数据最终以块（Block）的形式存储在磁盘或SSD上，存储管理器负责高效读写。

## 第二章 索引结构

#### B+树索引的原理及优化

###### B+树的核心原理

- **节点类型**：
  - **内部节点（非叶节点）**：仅存储键（Key）和指向子节点的指针。
  - **叶子节点**：存储键和对应的数据指针（如记录的物理地址或主键值）。
  - **叶子节点间的双向链表**：支持高效的范围查询（范围扫描只需遍历链表）。
  
- **键的分布规则**：
  - 每个节点的键按升序排列。
  - 对于`m`阶B+树，每个节点最多有`m-1`个键，至少`⌈m/2⌉-1`个键（根节点除外）。
  
- **平衡性**：所有叶子节点位于同一层，保证查询效率稳定。

- **数据存储位置**：

  - B树的所有节点均可存储数据。

  - B+树的数据仅存储在叶子节点，内部节点仅作索引导航。

- **范围查询效率**：B+树通过叶子链表支持高效顺序访问，而B树需回溯到父节点

###### B+树的优化策略

- **节点大小与磁盘块对齐**

  - 节点大小通常设置为磁盘块（如4KB/16KB）的整数倍，减少I/O次数。

  - **优化场景**：SSD随机访问友好，可适当减小节点大小。

- **填充因子（Fill Factor）**

  - 控制节点的填充比例（如70%~90%），预留空间减少分裂频率。

  - **动态调整**：根据插入/删除频率动态调整填充因子。

- **预分裂（Pre-splitting）**

  - 在插入前预测热点区域，提前分裂节点，减少并发冲突。

  - **适用场景**：高并发插入（如时序数据库的时间戳索引）。

- **延迟合并（Lazy Merging）**

  - 删除后不立即合并节点，而是标记为“可重用”，减少写放大。

  - **权衡**：可能增加查询时的碎片化。

- **批量加载（Bulk Loading）**
  - 对大规模数据初始化构建B+树时，按排序顺序批量插入，避免频繁分裂。
  - 排序所有键。
  - 自底向上构建叶子节点，再递归构建内部节点。

- **缓存优化**
  - **热节点缓存**：将频繁访问的内部节点（如根及其子节点）驻留内存。

  - **Bloom Filter**：在叶子节点前添加布隆过滤器，加速键不存在判断。


###### B+树在数据库中的应用

- **聚簇索引（Clustered Index）**

  - 叶子节点直接存储数据行（如InnoDB的主键索引）。

  - **优势**：主键范围查询高效（数据物理有序）。

- **二级索引（Secondary Index）**
  - 叶子节点存储主键值，回表查询需要额外I/O。
  
  - **覆盖索引优化**：若查询字段全部在索引中，无需回表。
  
- **联合索引（Composite Index）**：按多列组合构建索引，支持最左前缀匹配查询。

#### 哈希索引

###### 哈希索引的核心原理

- **哈希函数（Hash Function）**：
  - 将任意长度的键映射为固定范围的哈希值（如取模运算 `h(key) = key % N`）。
  - 理想哈希函数需满足：均匀分布、低冲突率、计算高效。
  - 常见哈希函数：MD5、SHA-1（用于校验）、MurmurHash（数据库常用）。
- **哈希桶（Bucket）**
  - 每个哈希值对应一个桶（Bucket），桶内存储键值对或数据指针。
  - 桶可以是内存中的数组单元或磁盘上的数据块。

###### 静态哈希（Static Hashing）

- **直接哈希表**：桶数量固定（如`N=1000`），哈希函数为`h(key) = key % N`。
- **溢出处理**：
  - **开放寻址法（Open Addressing）**：冲突时按规则（如线性探测、二次探测）寻找下一个空桶。
  - **链地址法（Chaining）**：每个桶内维护链表（内存）或溢出页（磁盘），存储冲突键值对。

###### 动态哈希（Dynamic Hashing）

- **目录结构**：
  - 目录是一个指针数组，每个条目指向一个桶。
  - 目录的深度（Global Depth）决定哈希值的有效位数（如深度=3时，使用哈希值的前3位）。
- **桶的局部深度（Local Depth）**：
  - 每个桶记录自身使用的哈希值位数（≤目录深度）。
  - 当桶溢出时，增加局部深度并分裂桶，必要时扩展目录。

- **线性哈希（Linear Hashing）**

  - **桶数量`n`**：初始为2，按需线性增长（每次增加1个桶）。

  - **哈希函数族**：使用多个哈希函数（如`h_i(key) = key % (2^i * n_0)`），逐步切换。

  - **分裂指针（Split Pointer）**：指向下一个待分裂的桶，分裂后指针移动。

###### 静态哈希 vs. 动态哈希对比

| **特性**       | **静态哈希**         | **动态哈希**                 |
| :------------- | :------------------- | :--------------------------- |
| **桶数量**     | 固定                 | 动态增长                     |
| **空间利用率** | 可能浪费或不足       | 按需分配，利用率较高         |
| **扩容成本**   | 需重建全表           | 渐进式扩展（如分裂桶）       |
| **实现复杂度** | 简单                 | 复杂（需处理目录或分裂指针） |
| **适用场景**   | 数据量稳定、点查频繁 | 数据量变化大、需弹性扩展     |
| **典型实现**   | 链地址法、开放寻址法 | 可扩展哈希、线性哈希         |

#### 多级索引与复合键索引

###### 多级索引（Multi-level Index）

- **定义**：**多级索引**是通过在现有索引之上再建立索引（即索引的索引），形成层级结构，减少查询时的磁盘I/O次数。

- **核心思想**：将大型索引分解为多层，每层索引管理下一层索引的地址，类似“目录的目录”。

- **典型应用**：

  - 主索引（Primary Index）上建立辅助索引（Secondary Index）。

  - 分区数据（如分库分表）中全局索引的构建。

- **层级划分**：
  - **第一级索引（主索引）**：直接指向数据记录的物理地址。
  - **第二级索引**：指向第一级索引的块或键范围。
  - **更高层级**：依此类推，形成树状结构。
- **插入数据**：
  - 更新主索引，插入新记录的键和地址。
  - 若主索引块溢出，触发分裂并同步更新二级索引。
- **查询数据**：从最顶层索引开始逐层定位，最终到达主索引和数据块。

###### 复合键索引（Composite Key Index）

- **复合键索引**（又称联合索引）是将多个列（字段）组合为一个索引键，按列顺序构建索引结构（如B+树）。
- **核心思想**：通过多列组合的排序，支持多条件查询的最左前缀匹配。
- **典型应用**：
  - 加速`WHERE col1=val1 AND col2=val2`类查询。
  - 覆盖索引（Covering Index）避免回表查询。
- **键的组成**：索引键由多个列值按定义顺序拼接而成（如`(col1, col2, col3)`）。
- **排序规则**：按列顺序逐级排序（先按`col1`排序，`col1`相同再按`col2`排序，依此类推）。
- **最左前缀匹配**：查询条件必须包含复合索引的最左连续列，否则索引失效。
- **列顺序选择**：高频查询条件列放在最左侧；区分度高的列（Cardinality高）优先；范围查询列尽量靠后。
- **覆盖索引优化**：若索引包含所有查询字段（如`SELECT col1, col2`且索引为`(col1, col2)`），无需回表查询数据页。
- **索引下推（Index Condition Pushdown, ICP）**：在存储引擎层直接利用索引过滤数据，减少回表次数（如MySQL 5.6+支持）。

## 第三章 查询执行基础

#### SQL查询的物理实现

###### 选择（σ）的物理实现

**1.全表扫描（Sequential Scan）**

- **适用场景**：无索引、条件选择性低（大量数据需读取）。
- **实现方式**：按数据块顺序读取所有磁盘页；逐行检查条件，过滤出符合要求的元组。
- **优化策略**：
  - **预读（Prefetching）**：提前加载连续块，减少I/O等待。
  - **多线程并行扫描**：分块并行处理（如PostgreSQL的并行查询）。

**2.索引扫描（Index Scan）**

- **适用场景**：条件列存在索引（如B+树、哈希索引），且选择性高。
- **实现方式**：通过索引结构快速定位符合条件的键值；根据索引指针（如行ID）回表获取完整数据（聚簇索引可直接获取）。
- **优化策略**：
  - **覆盖索引（Covering Index）**：索引包含查询所需列，避免回表。
  - **索引条件下推（Index Condition Pushdown）**：在索引层直接过滤条件（如MySQL的ICP）。

**3.多条件处理**

- **合取条件（AND）**：优先使用选择性高的条件过滤，减少后续处理量。
- **析取条件（OR）**：可能需要合并多个索引结果（如位图索引合并）。

###### 投影（π）的物理实现

 **1. 列裁剪（Early Projection）**

- **原理**：尽早去除无关列，减少内存和I/O开销。
- **实现方式**：在扫描或连接过程中仅保留所需列，而非读取整行；物化时仅存储必要列（如列式存储优化）。

**2. 去重（Duplicate Elimination）**

- **排序去重**：
  - **适用场景**：数据需排序输出（如含`ORDER BY`）。
  - **实现方式**：对结果集按投影列排序；遍历排序后数据，跳过重复值。
- **哈希去重**：
  - **适用场景**：内存充足，无需排序。
  - **实现方式**：构建哈希表，键为投影列组合；插入时检查哈希冲突，丢弃重复值。

###### 连接（⨝）的物理实现

**1. 嵌套循环连接（Nested Loop Join）**

- **实现方式**：外层循环遍历驱动表（小表）的每一行；内层循环遍历被驱动表（大表），检查连接条件。
- **优化策略**：
  - **块嵌套循环（Block Nested Loop）**：分块读取内层表，减少I/O次数。
  - **索引嵌套循环**：内层表连接列有索引时，直接索引查找（避免全表扫描）。

**2. 排序归并连接（Sort-Merge Join）**

- **实现方式**：对两表按连接键排序；双指针遍历有序表，合并匹配行。
- **适用场景**：数据已排序或需排序输出；连接条件为非等值（如`BETWEEN`），但较少见。

**3. 哈希连接（Hash Join）**

- **实现方式**：

  - **构建阶段**：对小表（构建表）按连接键构建哈希表。

  - **探测阶段**：扫描大表（探测表），通过哈希表查找匹配行。

- **优化策略**：

  - **分区哈希（Partitioned Hash Join）**：若内存不足，将两表按哈希分区，逐分区处理。
  - **布隆过滤器（Bloom Filter）**：预过滤不可能匹配的行，减少探测开销。

**4. 索引连接（Index Join）**

- **实现方式**：扫描驱动表，提取连接键；利用被驱动表的索引（如B+树）查找匹配行。
- **适用场景**：被驱动表连接列有高效索引。

###### 集合操作的物理实现

**1. 并集（UNION）**

- **去重实现**：
  - 排序后去重：合并两输入流，跳过重复值。
  - 哈希去重：构建哈希表，插入时去重。
- **不去重实现（UNION ALL）**：直接合并两输入流，无额外开销。

**2. 交集（INTERSECT）与差集（EXCEPT）**

- **排序实现**：对两输入排序；双指针遍历，输出共有行（交集）或独有行（差集）。
- **哈希实现**：对较小表构建哈希表；扫描另一表，检查存在性（交集）或不存在性（差集）。

###### 聚合（GROUP BY）与排序（ORDER BY）的物理实现

**1. 聚合（Aggregation）**

- **哈希聚合**：构建哈希表，键为分组列；更新每组的聚合值（如SUM、COUNT）。
- **排序聚合**：按分组列排序；遍历有序数据，逐组计算聚合值。
- **优化策略**：流式聚合，若数据已按分组列排序，无需全量缓存。

**2. 排序（Sorting）**

- **内存排序**：使用快速排序（QuickSort）或归并排序（MergeSort）。
- **外排序（External Sort）**：将数据分块排序后写入磁盘；多路归并（K-way Merge）生成最终有序结果。

#### 迭代器模型

###### 迭代器模型的核心设计

- **迭代器接口**

  - **`Open()`**：初始化操作符状态（如打开文件、分配内存）。

  - **`Next()`**：请求下一行（或下一批）数据，返回结果或标记结束（EOF）。

  - **`Close()`**：释放资源（如关闭文件、清理内存）。

- **拉取式执行（Pull-Based）**

  - 根节点调用`Next()`。

  - 根节点向下调用子节点的`Next()`，直到叶子节点（如`Scan`）。

  - 数据自底向上逐层处理，最终返回给用户。
  - 数据流由根操作符（如`Project`）通过递归调用`Next()` **主动拉取**。

- **流水线执行**：无需物化中间结果，数据流经操作符时逐行处理，减少内存占用。

###### 迭代器模型的实现示例

- **扫描操作符（Scan）**：从磁盘读取表数据。

- **选择操作符（Filter）**：根据条件过滤元组。

- **投影操作符（Project）**：提取并返回指定列。

###### 迭代器模型的执行流程

- **示例查询计划**

```SQL
SELECT name FROM employees WHERE age > 30;
```

- **物理计划树**：

```markdown
Project(name)
│
└── Filter(age > 30)
    │
    └── Scan(employees)
```

- **根节点调用链**：`Project.Open()` → `Filter.Open()` → `Scan.Open()`。

- **数据拉取**：

  - `Project.Next()` → 调用 `Filter.Next()` → 调用 `Scan.Next()`。

  - `Scan` 返回一行原始数据（如 `{name: "Alice", age: 35}`）。

  - `Filter` 检查 `age > 30`，若通过则返回该行。
  - `Project` 提取 `name` 列，返回最终结果 `"Alice"`。

- **终止条件**：当 `Scan.Next()` 返回 EOF 时，逐层终止。

#### 物化与流水线执行策略

###### 物化（Materialization）

- **原理**：将中间结果写入临时表，供后续操作读取。
- **适用场景**：中间结果过大，无法在内存中处理；需多次访问同一结果（如子查询结果复用）。

###### 流水线执行（Pipelining）

- **原理**：将多个操作的执行过程重叠，减少中间结果物化。
- **示例**：选择→投影→连接可流水线执行，避免将中间结果写入磁盘。
- **限制**：需操作间支持数据流式传递（如无需全量数据）。

## 第四章 查询优化技术

#### 逻辑查询优化

###### 逻辑优化的核心思想

- **等价性保证**：优化后的逻辑计划必须与原查询语义等价（返回相同结果）。
- **减少中间结果**：尽早过滤无关数据、减少参与运算的元组数量。
- **利用代数定律**：基于关系代数的交换律、结合律、分配律等规则重组操作。

###### 逻辑优化的主要技术

- **选择操作（σ）下推（Predicate Pushdown）**
  - **原理**：将过滤条件尽可能靠近数据源，减少后续操作处理的数据量。
  - **适用场景**：过滤条件作用于单表（如`WHERE`、`ON`中的条件）；过滤条件的选择性高（过滤后数据显著减少）。
- **投影操作（π）下推（Projection Pushdown）**
  - **原理**：尽早去除查询中不需要的列，减少数据传输和内存占用。
  - **适用场景**：查询仅需部分列（避免读取宽表的全部字段）；列包含大字段（如`TEXT`、`BLOB`）。
- **连接操作（⨝）重排序（Join Reordering）**：
  - **原理**：调整连接顺序，优先执行能减少中间结果大小的连接。
  - 先连接小表或高选择性条件的表。
  - 避免生成大型中间表（如笛卡尔积）。
  - **代价模型辅助**：结合统计信息（如表大小、索引）选择最优顺序。

- **子查询优化**
  - **子查询展开（Subquery Unnesting）**：将相关子查询转换为连接操作。
  - **子查询提升（Subquery Promotion）**：将`IN`、`EXISTS`子查询转换为半连接（Semi-Join）。
- **消除冗余操作**
  - **重复表达式消除**：合并相同计算（如重复的聚合或函数调用）。
  - **公共子表达式提取**：将重复子查询提取为临时表。
  - **冗余连接消除**：移除不必要的自连接或重复连接条件。
- **视图合并（View Merging）**：将视图的定义（子查询）合并到主查询中，避免物化视图的中间结果。
- **常量折叠（Constant Folding）**：在编译时计算常量表达式，减少运行时开销。

#### 基于代价的优化

###### 基于代价优化的核心流程

- **生成候选计划**：通过逻辑优化后的查询结构，生成多个可能的物理执行计划（如不同连接顺序或扫描方式）。

- **代价估算**：利用统计信息和代价模型，计算每个计划的预估代价。

- **选择最优计划**：对比所有候选计划，选择代价最低的方案执行。

###### 统计信息（Statistics）

- **表大小**：总行数（`n_rows`）、数据块（Page）数量。
- **列级统计信息**：
  - **基数（Cardinality）**：列中不同值的数量（如`COUNT(DISTINCT user_id)`）。
  - **数据分布**：直方图（Histogram）、最常值（MCV）、空值比例。
  - **范围信息**：最小值（Min）、最大值（Max）。
- **索引统计信息**
  - **索引大小**：索引树的高度、叶子节点数。
  - **索引选择性**：索引键的唯一性比例（如唯一索引选择性为1）。

###### 代价模型

- **I/O代价**

  - **顺序I/O代价**：连续读取数据块的代价（如`cost_seq_page = 1.0`）。

  - **随机I/O代价**：磁盘寻道+旋转延迟的代价（如`cost_random_page = 4.0`）。

- **CPU代价**：解析、比较、计算表达式的开销（如`cost_tuple = 0.01`）。

- **内存代价**：排序/哈希内存，若内存不足触发磁盘溢出，代价急剧上升。

- **网络代价（分布式数据库）**：数据传输开销，跨节点传输数据量（如`cost_network = data_size * 0.1`）。

#### 连接顺序优化

###### 动态规划（Dynamic Programming）

- **核心思想**：自底向上合并子计划，保存每个子集的最优解，避免重复计算。
- **步骤**：
  - **单表访问**：计算每个表的扫描代价（如全表扫描或索引扫描）。
  
  - **两表连接**：枚举所有两表连接组合，计算每种组合的代价，保留最优解。
  
  - **多表扩展**：逐步合并更多表，基于已保存的子计划生成新计划。
  
  - **最终选择**：从所有覆盖全表的计划中选取代价最低者。
- **搜索空间剪枝**：
  - **左深树（Left-Deep Tree）**：仅考虑左子节点为基表的连接树（如`(A⨝B)⨝C`），牺牲部分最优性以降低复杂度。
  - **浓密树（Bushy Tree）**：允许任意形状的连接树（如`(A⨝B)⨝(C⨝D)`），搜索空间更大但可能更优。

###### 贪心算法（Greedy Algorithm）

- **核心思想**：每一步选择局部最优的连接，减少计算量。
- **启发式规则**：
  - **最小中间结果优先**：优先连接结果集较小的表。
  - **高选择性优先**：优先使用选择性高的连接条件（如主外键关联）。
- **步骤**：
  
  - 选择代价最低的两表连接作为初始计划。
  
  - 逐步将剩余表中代价最低的加入当前计划。

## 第五章 连接算法详解

#### 数据库连接算法

###### 嵌套循环连接（Nested Loop Join）

- **实现方式**：外层循环遍历驱动表（小表）的每一行；内层循环遍历被驱动表（大表），检查连接条件。
- **优化策略**：
  - **块嵌套循环（Block Nested Loop）**：分块读取内层表，减少I/O次数。
  - **索引嵌套循环**：内层表连接列有索引时，直接索引查找（避免全表扫描）。

###### 排序归并连接（Sort-Merge Join）

- **实现方式**：对两表按连接键排序；双指针遍历有序表，合并匹配行。
- **适用场景**：数据已排序或需排序输出；连接条件为非等值（如`BETWEEN`），但较少见。

###### 哈希连接（Hash Join）

- **实现方式**：

  - **构建阶段**：对小表（构建表）按连接键构建哈希表。

  - **探测阶段**：扫描大表（探测表），通过哈希表查找匹配行。

- **优化策略**：

  - **分区哈希（Partitioned Hash Join）**：若内存不足，将两表按哈希分区，逐分区处理。
  - **布隆过滤器（Bloom Filter）**：预过滤不可能匹配的行，减少探测开销。

###### 索引连接（Index Join）

- **实现方式**：扫描驱动表，提取连接键；利用被驱动表的索引（如B+树）查找匹配行。
- **适用场景**：被驱动表连接列有高效索引。

## 第六章 事务与ACID特性

####  ACID特性

###### 原子性（Atomicity）

- **事务的原子性**：事务中的所有操作要么**全部成功提交**，要么**全部失败回滚**，不存在部分成功或部分失败的状态。
- **核心思想**：事务是不可分割的最小工作单元。
- **实现机制**
  - **撤销日志（UNDO Log）**：在事务执行过程中，记录修改前的旧值；若事务失败，根据UNDO日志回滚所有修改。
  - **两阶段提交协议（2PC）**：在分布式事务中协调多个节点，确保所有节点同时提交或回滚。

###### 一致性（Consistency）

- **数据库一致性**：事务执行前后，数据库必须从**一个一致的状态**转换到**另一个一致的状态**。
- **一致性内涵**：
  - **内部一致性**：满足数据库的完整性约束（如主键、外键、唯一性、CHECK约束）。
  - **业务逻辑一致性**：满足应用层定义的业务规则（如账户余额不能为负）。
- **实现机制**
  - **数据库约束**：通过主键、外键、触发器、CHECK约束等强制数据规则。
  - **原子性和隔离性**：原子性确保事务的修改完全生效/无效，避免中间状态破坏一致性；隔离性防止并发事务相互干扰导致不一致。

###### 隔离性（Isolation）

- **事务的隔离性**：多个并发执行的事务之间互不干扰，每个事务感知不到其他事务的存在。

- **理想目标**：达到**串行化（Serializable）**的执行效果，即并发执行结果与某种顺序的串行执行一致。

- **隔离性问题**

  - **脏读（Dirty Read）**：读取到其他事务未提交的数据。
  - **不可重复读（Non-Repeatable Read）**：同一事务内多次读取同一数据，结果不一致（因其他事务修改了数据）。
  - **幻读（Phantom Read）**：同一事务内多次查询同一范围，结果集不同（因其他事务插入或删除了数据）。

- **隔离级别**

  | **隔离级别**                     | **脏读** | **不可重复读** | **幻读** | **实现机制**               |
  | :------------------------------- | :------- | :------------- | :------- | :------------------------- |
  | **读未提交（Read Uncommitted）** | ✔️        | ✔️              | ✔️        | 无锁，直接读取最新数据     |
  | **读已提交（Read Committed）**   | ✖️        | ✔️              | ✔️        | 行级锁（写阻塞读），MVCC   |
  | **可重复读（Repeatable Read）**  | ✖️        | ✖️              | ✔️        | 快照隔离（MVCC）           |
  | **串行化（Serializable）**       | ✖️        | ✖️              | ✖️        | 范围锁（Next-Key Locking） |

- **实现机制**

  - **锁机制（Locking）**：共享锁（S锁）、排他锁（X锁）。
  - **多版本并发控制（MVCC）**：为每个事务生成数据快照，读操作不阻塞写操作（如InnoDB的Read View）。
  - **时间戳排序（Timestamp Ordering）**：按时间戳顺序处理事务冲突。

###### 持久性（Durability）

- **事务的持久性**：事务一旦提交，其对数据库的修改必须**永久保存**，即使系统发生故障（如断电、崩溃）也不丢失。
- **实现机制**
  - **预写式日志**：修改数据前，先将操作记录到事务日志（如REDO Log）；故障恢复时，通过重放日志恢复未持久化的数据。
  - **非易失性存储**：日志和数据最终写入磁盘或SSD。

###### ACID特性的整体性与权衡

- **特性间的依赖关系**
  - **原子性**是基础：回滚机制确保事务的“全或无”。
  - **隔离性**是手段：避免并发事务破坏一致性。
  - **一致性**是目标：通过原子性、隔离性、持久性共同实现。
  - **持久性**是保障：确保已提交事务的结果永久有效。
- **实际系统的权衡**
  - **性能与一致性**：高隔离级别（如串行化）会降低并发性能，需根据场景选择。
  - **分布式系统挑战**：在CAP定理中，网络分区时需在一致性（C）和可用性（A）间取舍（如BASE理论）。

#### 事务的状态机

###### 核心状态

- **活跃（Active）**、**部分提交（Partially Committed）**、**已提交（Committed）**、**失败（Failed）**、**中止（Aborted）**

- **状态转换图**

  ```
    开始  
     ↓  
  [Active] → 执行操作 → [Partially Committed]  
     |           ↑          |  
     |           |          ↓ 提交完成  
     ↓ 故障/回滚  |       [Committed]  
  [Failed] ←-----┘          |  
     |                      |  
     ↓ 回滚完成              |  
  [Aborted]                 |  
     └----------------------┘  
  ```

###### 活跃状态（Active）

- **定义**：事务已开始但尚未完成所有操作。
- **触发事件**：`BEGIN TRANSACTION` 或隐式事务启动。
- **可能转换**：
  - **→ 部分提交**：事务完成所有操作（执行到`COMMIT`前）。
  - **→ 失败**：事务执行中发生错误（如违反约束、死锁、显式`ROLLBACK`）。

###### 部分提交状态（Partially Committed）

- **定义**：事务已完成所有操作，但尚未将修改持久化到磁盘（日志或数据未完全落盘）。
- **触发事件**：事务执行完所有操作并发出`COMMIT`请求。
- **可能转换**：
  - **→ 已提交**：持久化完成（如日志写入磁盘）。
  - **→ 失败**：提交过程中发生故障（如系统崩溃）。

###### 已提交状态（Committed）

- **定义**：事务的修改已永久生效，其他事务可见其修改（取决于隔离级别）。
- **触发事件**：日志（如REDO日志）成功写入非易失存储。
- **后续操作**：释放事务占用的资源（如锁、内存）。

###### 失败状态（Failed）

- **定义**：事务无法继续正常执行（如死锁、约束冲突、用户回滚）。
- **触发事件**：显式`ROLLBACK`；隐式错误（如除零错误、唯一键冲突）。
- **可能转换**：**→ 中止**：执行回滚操作，撤销所有修改。

###### 中止状态（Aborted）

- **定义**：事务已回滚，数据库恢复到事务开始前的状态。
- **触发事件**：UNDO日志完成回滚，释放所有资源。
- **后续操作**：事务可被重启（需重新执行逻辑）。

## 第七章 并发控制机制

#### 锁机制

###### 核心锁类型

- **共享锁（S Lock，读锁）**
- **排他锁（X Lock，写锁）**
- **意向锁（Intention Locks）**：意向共享锁（IS）、意向排他锁（IX）

###### 锁的兼容性矩阵

| **当前锁\请求锁**  | **S（共享）** | **X（排他）** | **IS（意向共享）** | **IX（意向排他）** |
| :----------------- | :------------ | :------------ | :----------------- | :----------------- |
| **S（共享）**      | ✔️             | ✖️             | ✔️                  | ✖️                  |
| **X（排他）**      | ✖️             | ✖️             | ✖️                  | ✖️                  |
| **IS（意向共享）** | ✔️             | ✖️             | ✔️                  | ✔️                  |
| **IX（意向排他）** | ✖️             | ✖️             | ✔️                  | ✔️                  |

###### 锁的粒度

- **行级锁（Row-Level Lock）**

  - **定义**：锁定单行数据（如InnoDB的记录锁）。
  - **优点**：并发度高，冲突少。

  - **缺点**：锁管理开销大。

- **表级锁（Table-Level Lock）**

  - **定义**：锁定整张表（如MyISAM的写锁）。

  - **优点**：管理简单，开销小。

  - **缺点**：并发度低，易阻塞。

- **页级锁（Page-Level Lock）**

  - **定义**：锁定数据页（如SQL Server的页锁）。

  - **平衡点**：介于行锁和表锁之间。

###### 两阶段锁协议

- **阶段1：加锁（Growing Phase）**：事务可以申请新锁，但不能释放任何锁。

- **阶段2：解锁（Shrinking Phase）**：事务可以释放锁，但不能申请新锁。

- **作用**：保证可串行化调度，避免脏读、不可重复读等问题。

###### 锁升级与降级

- **锁升级（Lock Escalation）**

  - **场景**：行锁过多时，自动升级为表锁（减少锁数量）。

  - **风险**：可能降低并发度。

- **锁降级（Lock Downgrade）**

  - **场景**：X锁降级为S锁（允许其他事务读取）。

  - **实现**：显式操作（如提交前降级）。

###### 实际数据库的锁实现

- **MySQL InnoDB**

  - **记录锁（Record Lock）**：锁定索引记录。

  - **间隙锁（Gap Lock）**：锁定索引区间（防止幻读）。

  - **Next-Key Lock**：记录锁 + 间隙锁（RR隔离级别默认）。

- **Oracle**
  - **行级锁 + 多版本控制（MVCC）**：读不阻塞写。
  - **自动锁升级**：行锁过多时升级为表锁。

#### 多版本并发控制（MVCC）

###### 核心组件与机制

- **数据版本链**

  - **事务ID（Trx ID）**：创建该版本的事务ID。
  - **回滚指针（Rollback Pointer）**：指向旧版本的UNDO日志记录。
  - **删除标记（Delete Flag）**：标记该版本是否被删除。

- **事务ID与可见性**

  - **事务ID分配**：每个事务启动时分配唯一ID（单调递增），用于标识数据版本的可见性。

  - **ReadView（读视图）**：事务在读取数据时生成一个快照，包含：

    > `m_ids`：活跃（未提交）事务ID集合。
    >
    > `min_trx_id`：最小活跃事务ID。
    >
    > `max_trx_id`：下一个待分配事务ID。

- **可见性判断规则**

  - **版本创建事务（Trx ID）已提交**，且满足以下任一条件：

    > **Trx ID < min_trx_id**：版本在事务启动前已提交。
    >
    > **Trx ID不在活跃事务列表（m_ids）中**：版本由已提交事务生成。

  - **版本未被标记为删除**，或删除版本的事务对当前事务不可见。

###### MVCC工作流程

- **读操作-快照读（Snapshot Read）**：

  - 生成当前事务的`ReadView`。

  - 遍历数据版本链，找到对当前事务可见的最新版本。
  - 若版本被删除且不可见，返回空或跳过。

- **写操作-当前读（Current Read）**：

  - 加行级锁（X锁），确保写操作的独占性。
  - 生成新版本，更新版本链，记录UNDO日志。
  - 提交时标记新版本为已提交，释放锁。

###### MVCC与隔离级别

| **隔离级别**                        | **MVCC实现机制**                                             |
| :---------------------------------- | :----------------------------------------------------------- |
| **读未提交（Read Uncommitted）**    | 不使用MVCC，直接读取最新版本（可能脏读）。                   |
| **读已提交（Read Committed, RC）**  | 每次读操作生成新`ReadView`，读取已提交的最新版本（避免脏读，允许不可重复读）。 |
| **可重复读（Repeatable Read, RR）** | 事务首次读操作生成`ReadView`，后续读复用该视图（避免不可重复读和幻读）。 |
| **串行化（Serializable）**          | 退化为锁机制（Next-Key Locking），不使用MVCC。               |

#### 死锁检测与预防

###### 死锁检测

- **等待图（Wait-for Graph）**：检测事务间的循环等待。
- **超时机制**：若事务等待锁超过阈值，强制回滚。

###### 死锁解除

- **回滚代价最小的事务**：选择UNDO日志量少的事务终止。
- **示例**：事务T1持有R1的锁并等待R2，事务T2持有R2的锁并等待R1 → 系统终止T1或T2。

###### 死锁预防

- **按固定顺序访问资源**

  - **原理**：统一资源请求顺序，避免循环等待。

  - **示例**：所有事务必须先锁表A再锁表B，杜绝交叉申请。

- **设置锁超时机制**

  - **原理**：事务等待锁超时后主动回滚，释放资源。

  - **实现**：数据库参数（如 `innodb_lock_wait_timeout`）。

- **减少事务粒度**
  - **小事务**：避免长事务占用资源。
  - **低隔离级别**：如使用 `READ COMMITTED` 减少锁范围。

## 第八章 日志与恢复技术

#### 预写式日志

###### 核心原则

- **日志先行**：事务的修改操作（如插入、更新、删除）必须**先写入日志文件**，再更新内存中的数据页。
- **日志持久化**：日志记录必须**刷盘**（写入磁盘）后，才允许事务提交。

###### WAL 的工作流程

- **事务修改数据**：事务在内存中修改数据页（脏页），并生成对应的日志记录（如“修改行X，旧值A→新值B”）。
- **日志刷盘**：将日志记录写入磁盘的日志文件（确保持久化）。
- **数据刷盘**：异步将内存中的脏页写入磁盘数据文件（允许延迟，日志已保障安全）。

###### 日志内容

- **事务ID**：标识所属事务。
- **操作类型**：增、删、改。
- **数据位置**：如页号、行ID。
- **修改前后的值**（UNDO/REDO信息）。
- **提交标记**：事务提交时记录`COMMIT`。

###### 故障恢复

- **分析阶段**：识别未提交事务和已提交但未刷盘的事务。
- **重做（REDO）**：对已提交的事务，按日志**重新执行操作**（确保数据持久性）。
- **撤销（UNDO）**：对未提交的事务，按日志**回滚修改**（保证原子性）。

#### UNDO日志与REDO日志

###### UNDO日志

- **核心作用**

  - **原子性保障**：回滚未提交的事务，撤销其对数据的修改。

  - **多版本并发控制（MVCC）**：支持读取历史版本数据，实现非阻塞读（如读已提交隔离级别）。

- **日志内容**

  - **事务ID**：标识操作所属事务。
  - **操作类型**：插入（Insert）、删除（Delete）、更新（Update）。
  - **数据位置**：被修改记录的地址（如页号、行ID）。
  - **旧值**：修改前的数据状态。

- **工作流程**

  - **事务修改数据前**：将修改前的数据状态写入UNDO日志；日志写入磁盘或内存缓冲区（取决于实现）。

  - **事务执行中**：若需回滚（如用户显式`ROLLBACK`或系统检测到死锁），根据UNDO日志逐条恢复旧值。

  - **事务提交后**：UNDO日志可被清理（但需保留至不再被任何活跃事务引用，以支持MVCC）。

###### REDO日志

- **核心作用**

  - **持久性保障**：确保已提交事务的修改在崩溃后能恢复。

  - **加速数据写入**：允许脏页（内存中已修改但未刷盘的数据）延迟写入磁盘。

- **日志内容**

  - **事务ID**：标识操作所属事务。
  - **操作类型**：物理操作（如页号、偏移量、新数据字节）。
  - **LSN（Log Sequence Number）**：全局唯一的日志序列号，用于排序和恢复。

- **工作流程**

  - **事务修改数据时**：生成REDO日志，记录数据修改后的状态。
  - **日志刷盘**：提交事务前，REDO日志必须强制刷盘（通过`fsync`确保持久化）。
  - **数据刷盘**：脏页可异步写入磁盘（依赖后台线程定期刷盘）。
  - **崩溃恢复**：重放REDO日志，将已提交事务的修改重新应用到数据页。

#### 检查点（Checkpoint）机制

###### 检查点的作用

- **减少恢复时间**：崩溃后只需恢复检查点之后的日志，无需扫描全部日志。
- **释放日志空间**：清理已持久化的旧日志，避免日志文件无限增长。
- **提升性能**：批量刷盘脏页（内存中已修改的数据页），减少随机I/O。

######  检查点的基本流程

- **触发检查点**：
  - **定时触发**：如每隔5分钟自动执行。
  - **手动触发**：通过命令（如`CHECKPOINT`）强制执行。
  - **日志量阈值触发**：当日志文件达到一定大小时触发。
- **刷盘脏页**：将内存中所有已修改的脏页（Dirty Pages）写入磁盘数据文件。
- **记录检查点信息**：在日志中写入一条**检查点记录**，包含当前最大日志序列号（LSN）。
- **清理旧日志**：删除检查点之前不再需要的日志（已持久化的操作）。

###### 检查点类型

- **完全检查点（Full Checkpoint）**：刷盘所有脏页（耗时较长，影响性能，一般用于维护时段）。
- **模糊检查点（Fuzzy Checkpoint）**：允许脏页分批刷盘，记录检查点时无需暂停事务（现代数据库常用）。

#### ARIES恢复算法详解

###### 工作流程

- **分析阶段**：通过日志分析系统崩溃时，哪些任务需要重做，哪些需要回滚。
- **重做阶段**：不管之前有没有存盘，把所有提交成功的事务按日志重做一遍（防止中途断电漏存）。
- **回滚阶段**：把没执行完毕的事务按日志撤销，恢复原样。

###### 实现机制

- **日志序列号（LSN）**：每条日志有唯一编号，严格按顺序处理。
- **检查点（Checkpoint）**：定期存个“快照”，恢复时不用从头查日志。
- **反向日志（CLR）**：回滚时不用重复记日志，省时省力。

## 第九章 分布式数据库系统

#### 数据分片

###### 水平分片（Horizontal Sharding）

- **定义**：按行（记录）划分数据，不同分片存储不同的行子集。
- **分片键（Shard Key）**：用于划分数据的字段（如用户ID、时间戳）。
- **分片策略**
  - **范围分片（Range Sharding）**：按分片键的值范围划分（如用户ID 1-1000在分片1，1001-2000在分片2）。
  - **哈希分片（Hash Sharding）**：对分片键哈希取模，映射到不同分片（如`hash(user_id) % 3`）。
  - **列表分片（List Sharding）**：按分片键的枚举值分配（如地区字段值为“北京”的分片1，“上海”的分片2）。

###### 垂直分片（Vertical Sharding）

- **定义**：按列划分数据，不同分片存储不同的列子集。
- **优点**：减少单表宽度，提升高频字段查询性能。
- **缺点**：查询需跨分片关联（如`JOIN`操作），复杂度高。

###### 混合分片（Hybrid Sharding）

- **定义**：组合水平与垂直分片，先垂直拆分再水平扩展。

###### 分片键（Shard Key）的选择原则

- **高基数**：分片键的值应分布均匀（如用户ID而非性别）。
- **业务相关性**：分片键应匹配高频查询条件（如按订单时间分片支持时间范围查询）。
- **避免热点**：避免选择单调递增的键（如自增ID），导致写入集中在最新分片。
- **稳定性**：分片键的值应尽量不变（如用户ID而非手机号）。

###### 数据路由机制

- **客户端路由**：客户端根据分片规则直接连接目标分片。
- **代理层路由**：通过代理（如MySQL Router、ShardingSphere-Proxy）解析SQL并路由到对应分片。
- **协调节点路由**：由分布式数据库的协调节点（如CockroachDB的Gateway Node）统一管理路由。

#### 分布式事务

###### 两阶段提交（2PC，Two-Phase Commit）

- **协调者（Coordinator）**：主导事务的提交或中止决策。
- **参与者（Participant）**：执行本地事务并反馈状态。
- **阶段一：准备阶段（Prepare Phase）**
  - 协调者向所有参与者发送 `Prepare` 请求。
  - 参与者执行本地事务（不提交），记录 UNDO/REDO 日志，回复 `Yes` 或 `No`。

- **阶段二：提交阶段（Commit Phase）**

  - **若所有参与者回复 `Yes`**：协调者发送 `Commit` 命令，参与者提交事务。

  - **若有任一参与者回复 `No`**：协调者发送 `Rollback` 命令，参与者回滚事务。

###### 三阶段提交（3PC，Three-Phase Commit）

- **改进点**：引入超时机制和预提交阶段，减少阻塞风险。
- **CanCommit 阶段**：协调者询问参与者是否具备提交条件（避免资源浪费）。
- **PreCommit 阶段**：参与者预提交，锁定资源并反馈。
- **DoCommit 阶段**：协调者根据反馈决定提交或回滚。
- **基于 Paxos/Raft 的优化协议**：利用分布式共识算法（如Multi-Paxos）替代协调者，避免单点故障。

###### BASE 理论

- **基本可用（Basically Available）**：允许部分功能降级（如查询限流）。

- **软状态（Soft State）**：允许中间状态存在（如订单“处理中”）。

- **最终一致性（Eventually Consistent）**：数据最终一致，而非实时一致。

###### Saga 模式

- **核心思想**：将长事务拆分为多个本地事务，通过补偿操作回滚。
- **正向操作（T1, T2, ...）**：依次执行各子事务。
- **补偿操作（C1, C2, ...）**：若某子事务失败，逆向执行已提交的补偿操作。

###### TCC（Try-Confirm-Cancel）

- **Try**：预留资源（如冻结库存）。

- **Confirm**：确认操作（正式扣减库存）。

- **Cancel**：释放资源（解冻库存）。

- **适用场景**：高一致性要求的金融交易。

#### CAP理论与一致性模型

###### CAP理论

- **CAP三要素的定义**

  | **要素**                              | **定义**                                                     |
  | :------------------------------------ | :----------------------------------------------------------- |
  | **一致性（Consistency）**             | 所有节点在同一时刻看到的数据完全相同（强一致性）。           |
  | **可用性（Availability）**            | 每个请求都能在合理时间内获得非错误响应（即使部分节点故障）。 |
  | **分区容忍性（Partition Tolerance）** | 系统在网络分区（节点间通信中断）时仍能继续运行。             |

- **CP系统（放弃A）**：
  - **特点**：在网络分区时，牺牲可用性以保持一致性。
  - **示例**：HBase、ZooKeeper、传统关系型数据库集群。
  - **场景**：金融交易、计费系统等强一致性需求场景。
- **AP系统（放弃C）**：
  - **特点**：在网络分区时，牺牲一致性以保持可用性，采用最终一致性。
  - **示例**：Cassandra、DynamoDB、CouchDB。
  - **场景**：社交媒体、实时日志处理等高可用需求场景。
- **CA系统（放弃P）**：仅在无网络分区时同时满足C和A，实际中无法实现（网络分区不可避免）。

###### 一致性模型

- **强一致性（Strong Consistency）**

  - **定义**：所有读写操作表现为原子性，后续操作总能读取到最新写入的值。

  - **实现方式**：同步复制（如2PC协议）；全局锁或共识算法（如Paxos、Raft）。

- **最终一致性（Eventual Consistency）**

  - **定义**：若无新写入，所有节点最终会达成一致状态，允许中间状态不一致。

  - **实现方式**：异步复制（如Gossip协议）；冲突解决策略（如Last-Write-Win、向量时钟）。

- **因果一致性（Causal Consistency）**

  - **定义**：保证存在因果关系的操作顺序一致，无关操作可以乱序。

  - **实现方式**：跟踪操作依赖关系（如向量时间戳）。

- **会话一致性（Session Consistency）**

  - **定义**：同一会话内保证读写一致性，跨会话允许弱一致性。

  - **实现方式**：客户端会话绑定到固定节点（如Sticky Session）。

- **单调读一致性（Monotonic Reads）**

  - **定义**：同一客户端不会读到比之前更旧的数据。

  - **实现方式**：客户端记录最新版本号，读取时至少不低于该版本。

- **线性一致性（Linearizability）**：所有操作按全局顺序执行，且实时生效（强一致性的子集）。

#### Paxos与Raft算法

###### Paxos算法

- **角色定义**

  - **Proposer**：提出提案（如写入请求）。

  - **Acceptor**：接受或拒绝提案，存储已接受的提案。

  - **Learner**：学习最终被选中的提案（可选角色）。

- **阶段1：Prepare（准备）**

  - **Proposer生成提案号**：选择一个全局唯一的递增编号`n`（如时间戳+节点ID）。

  - **广播Prepare请求**：向所有Acceptor发送`Prepare(n)`。

  - **Acceptor响应**：若`n`是收到过的最大的提案号，则返回已接受的最高编号提案（若有），并承诺不再接受比`n`小的提案，否则拒绝请求。

- **阶段2：Accept（接受）**

  - **Proposer选择提案值**：若收到多数派Acceptor的响应，选择响应中最高编号的提案值（若存在），否则使用自己的值。

  - **广播Accept请求**：发送`Accept(n, value)`。

  - **Acceptor接受提案**：若未承诺过更大的提案号，则接受`(n, value)`并持久化。

  - **Learner学习最终值**：当多数派Acceptor接受某提案时，该值被选定。

###### Raft算法

- **角色定义**

  - **Leader**：唯一处理客户端请求的节点，管理日志复制。

  - **Follower**：被动接收Leader的日志条目，参与选举。

  - **Candidate**：竞选Leader的临时状态。

- **Leader选举**

  - **超时触发选举**：Follower在选举超时（Election Timeout）未收到Leader心跳后，成为Candidate。

  - **发起投票请求**：Candidate向所有节点发送`RequestVote`请求。

  - **投票规则**：每个节点在一个任期内只能投一票；Candidate需获得多数派投票才能成为Leader。

  - **新Leader产生**：新Leader定期发送心跳（`AppendEntries`）维持权威。

- **日志复制**

  - **客户端请求处理**：Leader将请求追加到本地日志，标记为未提交（Uncommitted）。

  - **广播日志条目**：Leader向所有Follower发送`AppendEntries`请求。

  - **Follower确认**：Follower验证日志一致性后，追加条目并回复确认。

  - **提交日志**：当多数派Follower确认后，Leader提交日志（Committed），并通知Follower提交。

- **安全性保证**

  - **选举限制**：只有拥有最新日志的Candidate才能成为Leader（防止数据回滚）。

  - **日志匹配**：Leader强制覆盖Follower的不一致日志。

## 第十章 并行数据库技术

#### 并行查询处理

###### 数据分区（Data Partitioning）

- **水平分区**：按行分片（如哈希分区、范围分区）。

- **垂直分区**：按列分片（适合列式存储）。

- **混合分区**：结合水平与垂直分区（如行列混合存储）。

###### 并行扫描（Parallel Scan）

- **全表扫描并行化**：将表分片分配到多个节点，每个节点扫描本地分片；谓词下推（在存储层过滤无关数据）。

- **索引扫描并行化**：按索引范围拆分查询（如B+树的范围分区）。

###### 并行连接（Parallel Join）

- **分片对齐连接（Partitioned Join）**：将参与连接的表按连接键分片，相同键的分片在相同节点执行连接（如哈希连接）。

- **广播连接（Broadcast Join）**：小表复制到所有节点，与大表分片本地连接（减少网络传输）。

- **重分布连接（Repartition Join）**：按连接键重新分布数据，对齐分片后连接（适合大表间连接）。

###### 并行聚合（Parallel Aggregation）

- **局部聚合**：每个节点对本地数据执行局部聚合（如计算部分`SUM`）。
- **全局聚合**：合并局部结果生成全局聚合值（如汇总所有节点的`SUM`）。

###### 并行排序（Parallel Sort）

- **分片排序**：每个节点对本地分片排序。
- **归并**：合并所有有序分片（如多路归并）。

#### 共享内存/共享磁盘/无共享架构

###### 共享内存架构（Shared-Memory）

- 多个处理器共享同一内存和磁盘，通过内存通信交换数据。
- **优点**：通信延迟低，数据共享高效。
- **缺点**：扩展性受限（内存带宽瓶颈）。
- **应用场景**：单机多核并行（如Oracle Real Application Clusters）。

###### 共享磁盘架构（Shared-Disk）

- **特点**：多个节点共享磁盘存储，但各自拥有独立内存。
- **优点**：数据持久化集中管理，扩展性较好。
- **缺点**：磁盘I/O可能成为瓶颈。
- **应用场景**：传统数据仓库（如IBM DB2 PureScale）。

###### 无共享架构（Shared-Nothing）

- **特点**：每个节点独立管理自己的内存和磁盘，节点间通过网络通信。

- **优点**：扩展性强，适合超大规模数据。

- **缺点**：网络通信开销较大。

- **应用场景**：分布式数据库（如Teradata、Greenplum）。

## 第十一章 新兴数据库技术

#### 列式存储与OLAP优化

###### 列式存储 vs. 行式存储

| **特性**     | **行式存储（Row Store）**                            | **列式存储（Column Store）**                   |
| :----------- | :--------------------------------------------------- | :--------------------------------------------- |
| **数据布局** | 按行连续存储（如`[id, name, age], [id, name, age]`） | 按列独立存储（如所有`id`连续，所有`name`连续） |
| **适用场景** | OLTP（高并发事务，频繁插入/更新）                    | OLAP（复杂聚合查询，批量读取）                 |
| **读取效率** | 适合读取整行数据（如用户信息查询）                   | 适合读取部分列（如统计`SUM(age)`）             |
| **写入效率** | 高效（单行写入连续存储）                             | 较低（需更新多列位置，LSM树优化后可缓解）      |
| **压缩效率** | 低（行内数据类型多样，压缩率低）                     | 高（同列数据类型一致，压缩率高）               |

###### 列式存储的OLAP优化技术

- **数据压缩**

  - **字典编码（Dictionary Encoding）**：将重复值（如`country`列中的“中国”）映射为短整数，存储字典和编码值。

  - **位图压缩（Bitmap Encoding）**：对低基数列（如性别）使用位图标记存在性，结合游程编码（RLE）压缩。

  - **增量编码（Delta Encoding）**：存储相邻值的差值（如时间戳列），减少存储空间。

- **向量化处理（Vectorized Processing）**

  - **批处理模式**：每次处理一批数据（如1024行），而非逐行处理。

  - **SIMD优化**：利用CPU单指令多数据指令加速数值计算（如`SUM`、`AVG`）。

- **延迟物化（Late Materialization）**

  - **原理**：延迟将列数据拼接为行，仅在最终输出时组合所需列。

  - **优势**：减少中间结果的内存占用和计算开销。

- **列裁剪（Column Pruning）**

  - **优化逻辑**：仅读取查询涉及的列，忽略无关列。

  - **I/O节省**：若表有100列，查询仅需3列，I/O量减少97%。

- **内存与缓存优化**

  - **内存映射列数据**：将热数据保留在内存，加速多次访问。

  - **缓存元数据**：存储列统计信息（如`min`、`max`），加速过滤（如`WHERE age > 1000`可跳过整列）。

###### 列式存储的实际应用

- **文件格式**

  - **Apache Parquet**：列式存储格式，支持高效压缩和谓词下推;集成于Hadoop、Spark生态系统，适合大数据分析。

  - **ORC（Optimized Row Columnar）**：Hive原生列式格式，支持ACID事务（Hive 3+）。

- **列式数据库**

  - **ClickHouse**：高性能OLAP数据库，支持实时查询，采用MergeTree引擎合并数据块。

  - **Amazon Redshift**：基于列式存储的云数据仓库，支持MPP（大规模并行处理）。
  - **Google BigQuery**：Serverless列式存储，自动缩放，支持PB级数据分析。

###### OLAP场景的查询优化

- **聚合查询加速**

  - **预聚合（Pre-Aggregation）**：创建物化视图（Materialized View）存储常用聚合结果（如每日销售总额）。

  - **近似计算**：使用`approx_count_distinct`等函数，以精度换速度。

- **MPP架构**：将查询分解为多个子任务，在集群节点并行执行（如Presto、Doris）。

- **谓词下推**：将`WHERE`条件下推至存储引擎，减少数据传输量（如Parquet的过滤下推）。

#### 内存数据库

###### 内存型数据库的核心优势

| **特性**         | **内存型数据库**         | **传统磁盘数据库**               |
| :--------------- | :----------------------- | :------------------------------- |
| **数据存储位置** | 数据常驻内存，直接访问   | 数据存储在磁盘，需加载到内存处理 |
| **延迟**         | 微秒级（μs）             | 毫秒级（ms）                     |
| **吞吐量**       | 百万级QPS                | 千至万级QPS                      |
| **适用场景**     | 实时分析、高频交易、缓存 | 事务处理、持久化存储             |
| **硬件成本**     | 高（内存成本远高于磁盘） | 低                               |

###### 数据存储与结构优化

- **列式存储**：适合分析型负载（OLAP），如SAP HANA，通过列压缩和向量化计算加速聚合查询。
- **哈希表与跳跃表**：Redis使用哈希表实现键值存储，跳跃表支持有序集合的高效范围查询。
- **T树（T-Tree）**：平衡二叉树变种，适合内存中的范围查询和插入操作（如MemSQL）。

###### 持久化机制

- **快照（Snapshotting）**：定期将内存数据全量转储到磁盘（如Redis的RDB）。
- **日志追加（Append-Only Log, AOF）**：记录所有写操作日志，如Redis的AOF文件。
- **混合持久化**：结合快照与日志（如Redis的RDB+AOF），平衡性能与可靠性。

###### 并发控制

- **乐观锁（Optimistic Locking）**：假设冲突概率低，提交时检查版本号（如CAS操作），减少锁争用。
- **无锁数据结构**：使用原子操作（如Compare-and-Swap）实现并发安全（如Disruptor框架）。
- **多版本并发控制（MVCC）**：VoltDB通过时间戳管理数据版本，支持高并发读写。

###### 查询优化

- **即时编译（JIT）**：将查询编译为机器码执行，减少解释开销（如SAP HANA）。
- **向量化处理**：批量处理数据，利用SIMD指令加速计算（如ClickHouse的内存模式）。

###### 典型内存数据库对比

| **数据库**        | **类型**   | **核心特性**                             | **适用场景**             |
| :---------------- | :--------- | :--------------------------------------- | :----------------------- |
| **Redis**         | 键值存储   | 支持丰富数据结构（字符串、列表、哈希等） | 缓存、消息队列、实时统计 |
| **MemSQL**        | 关系型     | 支持SQL，列式与行式混合存储，分布式架构  | 实时分析、混合负载       |
| **SAP HANA**      | 列式分析型 | 内存计算、OLAP优化，集成机器学习         | 企业级实时BI、大数据分析 |
| **VoltDB**        | 关系型     | 事务型OLTP，ACID保证，高吞吐低延迟       | 金融交易、电信计费       |
| **Apache Ignite** | 分布式缓存 | 内存数据网格，支持SQL与分布式计算        | 分布式缓存、实时计算     |